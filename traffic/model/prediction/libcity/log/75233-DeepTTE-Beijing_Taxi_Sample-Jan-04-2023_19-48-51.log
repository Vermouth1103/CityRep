2023-01-04 19:48:51,434 - INFO - Log directory: ./libcity/log
2023-01-04 19:48:51,435 - INFO - Begin pipeline, task=eta, model_name=DeepTTE, dataset_name=Beijing_Taxi_Sample, exp_id=75233
2023-01-04 19:48:51,435 - INFO - {'task': 'eta', 'model': 'DeepTTE', 'dataset': 'Beijing_Taxi_Sample', 'saved_model': True, 'train': True, 'seed': 0, 'batch_size': 64, 'dataset_class': 'ETADataset', 'eta_encoder': 'DeeptteEncoder', 'executor': 'ETAExecutor', 'evaluator': 'ETAEvaluator', 'uid_emb_size': 16, 'weekid_emb_size': 3, 'timdid_emb_size': 8, 'kernel_size': 3, 'num_filter': 32, 'pooling_method': 'attention', 'num_final_fcs': 4, 'final_fc_size': 128, 'alpha': 0.1, 'rnn_type': 'LSTM', 'rnn_num_layers': 1, 'hidden_size': 128, 'max_epoch': 100, 'learner': 'adam', 'learning_rate': 0.001, 'lr_decay': False, 'clip_grad_norm': False, 'use_early_stop': False, 'patience': 20, 'num_workers': 0, 'min_session_len': 5, 'max_session_len': 50, 'min_sessions': 0, 'window_size': 1, 'cut_method': 'time_interval', 'pad_with_last_sample': True, 'sort_by_traj_len': True, 'cache_dataset': True, 'train_rate': 0.7, 'eval_rate': 0.1, 'gpu': True, 'gpu_id': 0, 'train_loss': 'none', 'epoch': 0, 'weight_decay': 0, 'lr_epsilon': 1e-08, 'lr_beta1': 0.9, 'lr_beta2': 0.999, 'lr_alpha': 0.99, 'lr_momentum': 0, 'lr_scheduler': 'multisteplr', 'lr_decay_ratio': 0.1, 'steps': [5, 20, 40, 70], 'step_size': 10, 'lr_T_max': 30, 'lr_eta_min': 0, 'lr_patience': 10, 'lr_threshold': 0.0001, 'max_grad_norm': 1.0, 'log_level': 'INFO', 'log_every': 1, 'load_best_epoch': True, 'hyper_tune': False, 'metrics': ['MAE', 'MAPE', 'MSE', 'RMSE', 'masked_MAE', 'masked_MAPE', 'masked_MSE', 'masked_RMSE', 'R2', 'EVAR'], 'mode': 'single', 'save_modes': ['csv'], 'geo': {'including_types': ['Polygon'], 'Polygon': {'coordinates': 'coordinate', 'embedding': 'other'}}, 'usr': {'properties': {}}, 'dyna': {'including_types': ['trajectory'], 'trajectory': {'entity_id': 'usr_id', 'traj_id': 'num', 'coordinates': 'coordinate', 'current_dis': 'num', 'speeds': 'other', 'speeds_relevant1': 'other', 'speeds_relevant2': 'other', 'speeds_long': 'other', 'grid_len': 'num', 'holiday': 'num'}}, 'geo_file': 'Beijing_Taxi_Sample_ori_longer20', 'usr_file': 'Beijing_Taxi_Sample_ori_longer20', 'dyna_file': 'Beijing_Taxi_Sample_ori_longer20', 'device': device(type='cuda', index=0), 'exp_id': 75233}
2023-01-04 19:48:53,048 - INFO - Loading file ./libcity/cache/dataset_cache/eta_Beijing_Taxi_Sample_DeeptteEncoder.json
2023-01-04 19:48:53,721 - INFO - longi_mean: 116.38167145561566
2023-01-04 19:48:53,722 - INFO - longi_std: 0.07416283805701834
2023-01-04 19:48:53,722 - INFO - lati_mean: 39.92553892677388
2023-01-04 19:48:53,723 - INFO - lati_std: 0.049981772271572
2023-01-04 19:48:53,723 - INFO - dist_mean: 8.814695989840317
2023-01-04 19:48:53,723 - INFO - dist_std: 7.073727325486173
2023-01-04 19:48:53,724 - INFO - time_mean: 1166.8956065318819
2023-01-04 19:48:53,724 - INFO - time_std: 973.9645727168944
2023-01-04 19:48:53,724 - INFO - dist_gap_mean: 0.3897806752549975
2023-01-04 19:48:53,724 - INFO - dist_gap_std: 0.22667483085183782
2023-01-04 19:48:53,724 - INFO - time_gap_mean: 51.59943780140807
2023-01-04 19:48:53,724 - INFO - time_gap_std: 44.83032982709822
2023-01-04 19:48:53,789 - INFO - Number of train data: 15432
2023-01-04 19:48:53,789 - INFO - Number of eval  data: 2200
2023-01-04 19:48:53,789 - INFO - Number of test  data: 4368
2023-01-04 19:48:58,188 - INFO - DeepTTE(
  (attr_net): Attr(
    (uid_em): Embedding(4968, 16)
    (weekid_em): Embedding(7, 3)
    (timeid_em): Embedding(1440, 8)
  )
  (spatio_temporal): SpatioTemporal(
    (geo_conv): GeoConv(
      (state_em): Embedding(2, 2)
      (process_coords): Linear(in_features=4, out_features=16, bias=True)
      (conv): Conv1d(16, 32, kernel_size=(3,), stride=(1,))
    )
    (rnn): LSTM(61, 128, batch_first=True)
    (attr2atten): Linear(in_features=28, out_features=128, bias=True)
  )
  (entire_estimate): EntireEstimator(
    (input2hid): Linear(in_features=156, out_features=128, bias=True)
    (residuals): ModuleList(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): Linear(in_features=128, out_features=128, bias=True)
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): Linear(in_features=128, out_features=128, bias=True)
    )
    (hid2out): Linear(in_features=128, out_features=1, bias=True)
  )
  (local_estimate): LocalEstimator(
    (input2hid): Linear(in_features=128, out_features=64, bias=True)
    (hid2hid): Linear(in_features=64, out_features=32, bias=True)
    (hid2out): Linear(in_features=32, out_features=1, bias=True)
  )
)
2023-01-04 19:48:58,191 - INFO - attr_net.uid_em.weight	torch.Size([4968, 16])	cuda:0	True
2023-01-04 19:48:58,192 - INFO - attr_net.weekid_em.weight	torch.Size([7, 3])	cuda:0	True
2023-01-04 19:48:58,192 - INFO - attr_net.timeid_em.weight	torch.Size([1440, 8])	cuda:0	True
2023-01-04 19:48:58,193 - INFO - spatio_temporal.geo_conv.state_em.weight	torch.Size([2, 2])	cuda:0	True
2023-01-04 19:48:58,193 - INFO - spatio_temporal.geo_conv.process_coords.weight	torch.Size([16, 4])	cuda:0	True
2023-01-04 19:48:58,194 - INFO - spatio_temporal.geo_conv.process_coords.bias	torch.Size([16])	cuda:0	True
2023-01-04 19:48:58,194 - INFO - spatio_temporal.geo_conv.conv.weight	torch.Size([32, 16, 3])	cuda:0	True
2023-01-04 19:48:58,194 - INFO - spatio_temporal.geo_conv.conv.bias	torch.Size([32])	cuda:0	True
2023-01-04 19:48:58,195 - INFO - spatio_temporal.rnn.weight_ih_l0	torch.Size([512, 61])	cuda:0	True
2023-01-04 19:48:58,196 - INFO - spatio_temporal.rnn.weight_hh_l0	torch.Size([512, 128])	cuda:0	True
2023-01-04 19:48:58,196 - INFO - spatio_temporal.rnn.bias_ih_l0	torch.Size([512])	cuda:0	True
2023-01-04 19:48:58,197 - INFO - spatio_temporal.rnn.bias_hh_l0	torch.Size([512])	cuda:0	True
2023-01-04 19:48:58,197 - INFO - spatio_temporal.attr2atten.weight	torch.Size([128, 28])	cuda:0	True
2023-01-04 19:48:58,198 - INFO - spatio_temporal.attr2atten.bias	torch.Size([128])	cuda:0	True
2023-01-04 19:48:58,198 - INFO - entire_estimate.input2hid.weight	torch.Size([128, 156])	cuda:0	True
2023-01-04 19:48:58,198 - INFO - entire_estimate.input2hid.bias	torch.Size([128])	cuda:0	True
2023-01-04 19:48:58,199 - INFO - entire_estimate.residuals.0.weight	torch.Size([128, 128])	cuda:0	True
2023-01-04 19:48:58,200 - INFO - entire_estimate.residuals.0.bias	torch.Size([128])	cuda:0	True
2023-01-04 19:48:58,200 - INFO - entire_estimate.residuals.1.weight	torch.Size([128, 128])	cuda:0	True
2023-01-04 19:48:58,201 - INFO - entire_estimate.residuals.1.bias	torch.Size([128])	cuda:0	True
2023-01-04 19:48:58,202 - INFO - entire_estimate.residuals.2.weight	torch.Size([128, 128])	cuda:0	True
2023-01-04 19:48:58,202 - INFO - entire_estimate.residuals.2.bias	torch.Size([128])	cuda:0	True
2023-01-04 19:48:58,203 - INFO - entire_estimate.residuals.3.weight	torch.Size([128, 128])	cuda:0	True
2023-01-04 19:48:58,204 - INFO - entire_estimate.residuals.3.bias	torch.Size([128])	cuda:0	True
2023-01-04 19:48:58,205 - INFO - entire_estimate.hid2out.weight	torch.Size([1, 128])	cuda:0	True
2023-01-04 19:48:58,205 - INFO - entire_estimate.hid2out.bias	torch.Size([1])	cuda:0	True
2023-01-04 19:48:58,206 - INFO - local_estimate.input2hid.weight	torch.Size([64, 128])	cuda:0	True
2023-01-04 19:48:58,207 - INFO - local_estimate.input2hid.bias	torch.Size([64])	cuda:0	True
2023-01-04 19:48:58,208 - INFO - local_estimate.hid2hid.weight	torch.Size([32, 64])	cuda:0	True
2023-01-04 19:48:58,208 - INFO - local_estimate.hid2hid.bias	torch.Size([32])	cuda:0	True
2023-01-04 19:48:58,209 - INFO - local_estimate.hid2out.weight	torch.Size([1, 32])	cuda:0	True
2023-01-04 19:48:58,210 - INFO - local_estimate.hid2out.bias	torch.Size([1])	cuda:0	True
2023-01-04 19:48:58,211 - INFO - Total parameter numbers: 290827
2023-01-04 19:48:58,212 - INFO - You select `adam` optimizer.
2023-01-04 19:48:58,214 - WARNING - Received none train loss func and will use the loss func defined in the model.
2023-01-04 19:48:58,214 - INFO - Start training ...
2023-01-04 19:48:58,215 - INFO - num_batches:242
2023-01-04 19:49:11,075 - INFO - epoch complete!
2023-01-04 19:49:11,076 - INFO - evaluating now!
2023-01-04 19:49:11,950 - INFO - Epoch [0/100] train_loss: 0.4573, val_loss: 0.2972, lr: 0.001000, 13.73s
2023-01-04 19:49:11,969 - INFO - Saved model at 0
2023-01-04 19:49:11,970 - INFO - Val loss decrease from inf to 0.2972, saving to ./libcity/cache/75233/model_cache/DeepTTE_Beijing_Taxi_Sample_epoch0.tar
