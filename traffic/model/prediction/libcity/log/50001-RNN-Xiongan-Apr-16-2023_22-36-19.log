2023-04-16 22:36:19,829 - INFO - Log directory: ./libcity/log
2023-04-16 22:36:19,829 - INFO - Begin pipeline, task=traffic_state_pred, model_name=GRU, dataset_name=Xiongan, exp_id=50001
2023-04-16 22:36:19,829 - INFO - {'task': 'traffic_state_pred', 'model': 'RNN', 'dataset': 'Xiongan', 'saved_model': True, 'train': True, 'exp_id': '50001', 'seed': 0, 'dataset_class': 'TrafficStatePointDataset', 'executor': 'TrafficStateExecutor', 'evaluator': 'TrafficStateEvaluator', 'rnn_type': 'GRU', 'hidden_size': 64, 'num_layers': 1, 'dropout': 0, 'bidirectional': False, 'teacher_forcing_ratio': 0, 'scaler': 'standard', 'load_external': True, 'normal_external': False, 'ext_scaler': 'none', 'add_time_in_day': True, 'add_day_in_week': False, 'max_epoch': 50, 'learner': 'adam', 'learning_rate': 0.01, 'lr_decay': True, 'lr_scheduler': 'multisteplr', 'lr_decay_ratio': 0.1, 'steps': [5, 20, 40, 70], 'clip_grad_norm': True, 'max_grad_norm': 5, 'use_early_stop': True, 'patience': 50, 'batch_size': 64, 'cache_dataset': True, 'num_workers': 0, 'pad_with_last_sample': True, 'train_rate': 0.7, 'eval_rate': 0.1, 'input_window': 12, 'output_window': 12, 'gpu': True, 'gpu_id': 0, 'train_loss': 'none', 'epoch': 0, 'weight_decay': 0, 'lr_epsilon': 1e-08, 'lr_beta1': 0.9, 'lr_beta2': 0.999, 'lr_alpha': 0.99, 'lr_momentum': 0, 'step_size': 10, 'lr_T_max': 30, 'lr_eta_min': 0, 'lr_patience': 10, 'lr_threshold': 0.0001, 'log_level': 'INFO', 'log_every': 1, 'load_best_epoch': True, 'hyper_tune': False, 'metrics': ['MAE', 'MAPE', 'MSE', 'RMSE', 'masked_MAE', 'masked_MAPE', 'masked_MSE', 'masked_RMSE', 'R2', 'EVAR'], 'evaluator_mode': 'single', 'save_mode': ['csv'], 'geo': {'including_types': ['Point'], 'Point': {}}, 'rel': {'including_types': ['geo'], 'geo': {'cost': 'num'}}, 'dyna': {'including_types': ['state'], 'state': {'entity_id': 'geo_id', 'traffic_speed': 'num'}}, 'data_col': ['traffic_speed'], 'weight_col': 'cost', 'data_files': ['Xiongan'], 'geo_file': 'Xiongan', 'rel_file': 'Xiongan', 'output_dim': 1, 'time_intervals': 300, 'init_weight_inf_or_zero': 'inf', 'set_weight_link_or_dist': 'dist', 'calculate_weight_adj': True, 'weight_adj_epsilon': 0.1, 'device': device(type='cuda', index=0)}
2023-04-16 22:36:19,837 - INFO - Loaded file Xiongan.geo, num_nodes=487
2023-04-16 22:36:19,839 - INFO - set_weight_link_or_dist: dist
2023-04-16 22:36:19,839 - INFO - init_weight_inf_or_zero: inf
2023-04-16 22:36:19,843 - INFO - Loaded file Xiongan.rel, shape=(487, 487)
2023-04-16 22:36:19,843 - INFO - Start Calculate the weight by Gauss kernel!
2023-04-16 22:36:19,846 - INFO - Loading ./libcity/cache/dataset_cache/point_based_Xiongan_12_12_0.7_0.1_standard_64_True_True_False_True.npz
2023-04-16 22:36:19,887 - INFO - train	x: (26, 12, 487, 2), y: (26, 12, 487, 2)
2023-04-16 22:36:19,887 - INFO - eval	x: (4, 12, 487, 2), y: (4, 12, 487, 2)
2023-04-16 22:36:19,887 - INFO - test	x: (7, 12, 487, 2), y: (7, 12, 487, 2)
2023-04-16 22:36:19,888 - INFO - StandardScaler mean: 59.92392878005366, std: 5.807862904711059
2023-04-16 22:36:19,888 - INFO - NoneScaler
2023-04-16 22:36:20,042 - INFO - You select rnn_type GRU in RNN!
2023-04-16 22:36:22,849 - INFO - RNN(
  (rnn): GRU(974, 64)
  (fc): Linear(in_features=64, out_features=487, bias=True)
)
2023-04-16 22:36:22,850 - INFO - rnn.weight_ih_l0	torch.Size([192, 974])	cuda:0	True
2023-04-16 22:36:22,850 - INFO - rnn.weight_hh_l0	torch.Size([192, 64])	cuda:0	True
2023-04-16 22:36:22,850 - INFO - rnn.bias_ih_l0	torch.Size([192])	cuda:0	True
2023-04-16 22:36:22,850 - INFO - rnn.bias_hh_l0	torch.Size([192])	cuda:0	True
2023-04-16 22:36:22,850 - INFO - fc.weight	torch.Size([487, 64])	cuda:0	True
2023-04-16 22:36:22,850 - INFO - fc.bias	torch.Size([487])	cuda:0	True
2023-04-16 22:36:22,850 - INFO - Total parameter numbers: 231335
2023-04-16 22:36:22,850 - INFO - You select `adam` optimizer.
2023-04-16 22:36:22,851 - INFO - You select `multisteplr` lr_scheduler.
2023-04-16 22:36:22,851 - WARNING - Received none train loss func and will use the loss func defined in the model.
2023-04-16 22:36:22,851 - INFO - Start training ...
2023-04-16 22:36:22,851 - INFO - num_batches:1
2023-04-16 22:36:22,902 - INFO - epoch complete!
2023-04-16 22:36:22,903 - INFO - evaluating now!
2023-04-16 22:36:22,919 - INFO - Epoch [0/50] train_loss: 5.0072, val_loss: 5.0799, lr: 0.010000, 0.07s
2023-04-16 22:36:22,927 - INFO - Saved model at 0
2023-04-16 22:36:22,927 - INFO - Val loss decrease from inf to 5.0799, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch0.tar
2023-04-16 22:36:22,964 - INFO - epoch complete!
2023-04-16 22:36:22,964 - INFO - evaluating now!
2023-04-16 22:36:22,983 - INFO - Epoch [1/50] train_loss: 5.0799, val_loss: 5.0446, lr: 0.010000, 0.06s
2023-04-16 22:36:22,990 - INFO - Saved model at 1
2023-04-16 22:36:22,991 - INFO - Val loss decrease from 5.0799 to 5.0446, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch1.tar
2023-04-16 22:36:23,026 - INFO - epoch complete!
2023-04-16 22:36:23,026 - INFO - evaluating now!
2023-04-16 22:36:23,045 - INFO - Epoch [2/50] train_loss: 5.0446, val_loss: 4.8182, lr: 0.010000, 0.05s
2023-04-16 22:36:23,052 - INFO - Saved model at 2
2023-04-16 22:36:23,052 - INFO - Val loss decrease from 5.0446 to 4.8182, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch2.tar
2023-04-16 22:36:23,089 - INFO - epoch complete!
2023-04-16 22:36:23,089 - INFO - evaluating now!
2023-04-16 22:36:23,111 - INFO - Epoch [3/50] train_loss: 4.8182, val_loss: 4.6643, lr: 0.010000, 0.06s
2023-04-16 22:36:23,118 - INFO - Saved model at 3
2023-04-16 22:36:23,118 - INFO - Val loss decrease from 4.8182 to 4.6643, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch3.tar
2023-04-16 22:36:23,152 - INFO - epoch complete!
2023-04-16 22:36:23,153 - INFO - evaluating now!
2023-04-16 22:36:23,170 - INFO - Epoch [4/50] train_loss: 4.6643, val_loss: 4.5551, lr: 0.001000, 0.05s
2023-04-16 22:36:23,177 - INFO - Saved model at 4
2023-04-16 22:36:23,177 - INFO - Val loss decrease from 4.6643 to 4.5551, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch4.tar
2023-04-16 22:36:23,213 - INFO - epoch complete!
2023-04-16 22:36:23,214 - INFO - evaluating now!
2023-04-16 22:36:23,230 - INFO - Epoch [5/50] train_loss: 4.5551, val_loss: 4.5161, lr: 0.001000, 0.05s
2023-04-16 22:36:23,237 - INFO - Saved model at 5
2023-04-16 22:36:23,238 - INFO - Val loss decrease from 4.5551 to 4.5161, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch5.tar
2023-04-16 22:36:23,274 - INFO - epoch complete!
2023-04-16 22:36:23,275 - INFO - evaluating now!
2023-04-16 22:36:23,292 - INFO - Epoch [6/50] train_loss: 4.5161, val_loss: 4.4734, lr: 0.001000, 0.05s
2023-04-16 22:36:23,299 - INFO - Saved model at 6
2023-04-16 22:36:23,299 - INFO - Val loss decrease from 4.5161 to 4.4734, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch6.tar
2023-04-16 22:36:23,335 - INFO - epoch complete!
2023-04-16 22:36:23,335 - INFO - evaluating now!
2023-04-16 22:36:23,352 - INFO - Epoch [7/50] train_loss: 4.4734, val_loss: 4.4344, lr: 0.001000, 0.05s
2023-04-16 22:36:23,359 - INFO - Saved model at 7
2023-04-16 22:36:23,360 - INFO - Val loss decrease from 4.4734 to 4.4344, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch7.tar
2023-04-16 22:36:23,396 - INFO - epoch complete!
2023-04-16 22:36:23,397 - INFO - evaluating now!
2023-04-16 22:36:23,416 - INFO - Epoch [8/50] train_loss: 4.4344, val_loss: 4.3997, lr: 0.001000, 0.06s
2023-04-16 22:36:23,423 - INFO - Saved model at 8
2023-04-16 22:36:23,423 - INFO - Val loss decrease from 4.4344 to 4.3997, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch8.tar
2023-04-16 22:36:23,469 - INFO - epoch complete!
2023-04-16 22:36:23,470 - INFO - evaluating now!
2023-04-16 22:36:23,489 - INFO - Epoch [9/50] train_loss: 4.3997, val_loss: 4.3682, lr: 0.001000, 0.07s
2023-04-16 22:36:23,497 - INFO - Saved model at 9
2023-04-16 22:36:23,497 - INFO - Val loss decrease from 4.3997 to 4.3682, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch9.tar
2023-04-16 22:36:23,530 - INFO - epoch complete!
2023-04-16 22:36:23,531 - INFO - evaluating now!
2023-04-16 22:36:23,549 - INFO - Epoch [10/50] train_loss: 4.3682, val_loss: 4.3398, lr: 0.001000, 0.05s
2023-04-16 22:36:23,556 - INFO - Saved model at 10
2023-04-16 22:36:23,556 - INFO - Val loss decrease from 4.3682 to 4.3398, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch10.tar
2023-04-16 22:36:23,590 - INFO - epoch complete!
2023-04-16 22:36:23,590 - INFO - evaluating now!
2023-04-16 22:36:23,608 - INFO - Epoch [11/50] train_loss: 4.3398, val_loss: 4.3106, lr: 0.001000, 0.05s
2023-04-16 22:36:23,615 - INFO - Saved model at 11
2023-04-16 22:36:23,615 - INFO - Val loss decrease from 4.3398 to 4.3106, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch11.tar
2023-04-16 22:36:23,650 - INFO - epoch complete!
2023-04-16 22:36:23,650 - INFO - evaluating now!
2023-04-16 22:36:23,668 - INFO - Epoch [12/50] train_loss: 4.3106, val_loss: 4.2808, lr: 0.001000, 0.05s
2023-04-16 22:36:23,675 - INFO - Saved model at 12
2023-04-16 22:36:23,675 - INFO - Val loss decrease from 4.3106 to 4.2808, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch12.tar
2023-04-16 22:36:23,710 - INFO - epoch complete!
2023-04-16 22:36:23,710 - INFO - evaluating now!
2023-04-16 22:36:23,728 - INFO - Epoch [13/50] train_loss: 4.2808, val_loss: 4.2534, lr: 0.001000, 0.05s
2023-04-16 22:36:23,735 - INFO - Saved model at 13
2023-04-16 22:36:23,735 - INFO - Val loss decrease from 4.2808 to 4.2534, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch13.tar
2023-04-16 22:36:23,770 - INFO - epoch complete!
2023-04-16 22:36:23,771 - INFO - evaluating now!
2023-04-16 22:36:23,788 - INFO - Epoch [14/50] train_loss: 4.2534, val_loss: 4.2257, lr: 0.001000, 0.05s
2023-04-16 22:36:23,795 - INFO - Saved model at 14
2023-04-16 22:36:23,795 - INFO - Val loss decrease from 4.2534 to 4.2257, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch14.tar
2023-04-16 22:36:23,830 - INFO - epoch complete!
2023-04-16 22:36:23,830 - INFO - evaluating now!
2023-04-16 22:36:23,848 - INFO - Epoch [15/50] train_loss: 4.2257, val_loss: 4.1969, lr: 0.001000, 0.05s
2023-04-16 22:36:23,855 - INFO - Saved model at 15
2023-04-16 22:36:23,855 - INFO - Val loss decrease from 4.2257 to 4.1969, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch15.tar
2023-04-16 22:36:23,891 - INFO - epoch complete!
2023-04-16 22:36:23,892 - INFO - evaluating now!
2023-04-16 22:36:23,911 - INFO - Epoch [16/50] train_loss: 4.1969, val_loss: 4.1688, lr: 0.001000, 0.06s
2023-04-16 22:36:23,918 - INFO - Saved model at 16
2023-04-16 22:36:23,918 - INFO - Val loss decrease from 4.1969 to 4.1688, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch16.tar
2023-04-16 22:36:23,951 - INFO - epoch complete!
2023-04-16 22:36:23,951 - INFO - evaluating now!
2023-04-16 22:36:23,969 - INFO - Epoch [17/50] train_loss: 4.1688, val_loss: 4.1413, lr: 0.001000, 0.05s
2023-04-16 22:36:23,976 - INFO - Saved model at 17
2023-04-16 22:36:23,976 - INFO - Val loss decrease from 4.1688 to 4.1413, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch17.tar
2023-04-16 22:36:24,010 - INFO - epoch complete!
2023-04-16 22:36:24,011 - INFO - evaluating now!
2023-04-16 22:36:24,028 - INFO - Epoch [18/50] train_loss: 4.1413, val_loss: 4.1130, lr: 0.001000, 0.05s
2023-04-16 22:36:24,035 - INFO - Saved model at 18
2023-04-16 22:36:24,035 - INFO - Val loss decrease from 4.1413 to 4.1130, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch18.tar
2023-04-16 22:36:24,070 - INFO - epoch complete!
2023-04-16 22:36:24,070 - INFO - evaluating now!
2023-04-16 22:36:24,089 - INFO - Epoch [19/50] train_loss: 4.1130, val_loss: 4.0849, lr: 0.000100, 0.05s
2023-04-16 22:36:24,096 - INFO - Saved model at 19
2023-04-16 22:36:24,096 - INFO - Val loss decrease from 4.1130 to 4.0849, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch19.tar
2023-04-16 22:36:24,130 - INFO - epoch complete!
2023-04-16 22:36:24,130 - INFO - evaluating now!
2023-04-16 22:36:24,149 - INFO - Epoch [20/50] train_loss: 4.0849, val_loss: 4.0819, lr: 0.000100, 0.05s
2023-04-16 22:36:24,155 - INFO - Saved model at 20
2023-04-16 22:36:24,156 - INFO - Val loss decrease from 4.0849 to 4.0819, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch20.tar
2023-04-16 22:36:24,190 - INFO - epoch complete!
2023-04-16 22:36:24,190 - INFO - evaluating now!
2023-04-16 22:36:24,208 - INFO - Epoch [21/50] train_loss: 4.0819, val_loss: 4.0786, lr: 0.000100, 0.05s
2023-04-16 22:36:24,215 - INFO - Saved model at 21
2023-04-16 22:36:24,215 - INFO - Val loss decrease from 4.0819 to 4.0786, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch21.tar
2023-04-16 22:36:24,250 - INFO - epoch complete!
2023-04-16 22:36:24,250 - INFO - evaluating now!
2023-04-16 22:36:24,268 - INFO - Epoch [22/50] train_loss: 4.0786, val_loss: 4.0749, lr: 0.000100, 0.05s
2023-04-16 22:36:24,275 - INFO - Saved model at 22
2023-04-16 22:36:24,276 - INFO - Val loss decrease from 4.0786 to 4.0749, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch22.tar
2023-04-16 22:36:24,311 - INFO - epoch complete!
2023-04-16 22:36:24,311 - INFO - evaluating now!
2023-04-16 22:36:24,329 - INFO - Epoch [23/50] train_loss: 4.0749, val_loss: 4.0711, lr: 0.000100, 0.05s
2023-04-16 22:36:24,337 - INFO - Saved model at 23
2023-04-16 22:36:24,337 - INFO - Val loss decrease from 4.0749 to 4.0711, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch23.tar
2023-04-16 22:36:24,371 - INFO - epoch complete!
2023-04-16 22:36:24,371 - INFO - evaluating now!
2023-04-16 22:36:24,389 - INFO - Epoch [24/50] train_loss: 4.0711, val_loss: 4.0673, lr: 0.000100, 0.05s
2023-04-16 22:36:24,396 - INFO - Saved model at 24
2023-04-16 22:36:24,396 - INFO - Val loss decrease from 4.0711 to 4.0673, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch24.tar
2023-04-16 22:36:24,430 - INFO - epoch complete!
2023-04-16 22:36:24,431 - INFO - evaluating now!
2023-04-16 22:36:24,449 - INFO - Epoch [25/50] train_loss: 4.0673, val_loss: 4.0634, lr: 0.000100, 0.05s
2023-04-16 22:36:24,455 - INFO - Saved model at 25
2023-04-16 22:36:24,456 - INFO - Val loss decrease from 4.0673 to 4.0634, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch25.tar
2023-04-16 22:36:24,490 - INFO - epoch complete!
2023-04-16 22:36:24,490 - INFO - evaluating now!
2023-04-16 22:36:24,508 - INFO - Epoch [26/50] train_loss: 4.0634, val_loss: 4.0594, lr: 0.000100, 0.05s
2023-04-16 22:36:24,515 - INFO - Saved model at 26
2023-04-16 22:36:24,516 - INFO - Val loss decrease from 4.0634 to 4.0594, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch26.tar
2023-04-16 22:36:24,550 - INFO - epoch complete!
2023-04-16 22:36:24,551 - INFO - evaluating now!
2023-04-16 22:36:24,569 - INFO - Epoch [27/50] train_loss: 4.0594, val_loss: 4.0554, lr: 0.000100, 0.05s
2023-04-16 22:36:24,576 - INFO - Saved model at 27
2023-04-16 22:36:24,576 - INFO - Val loss decrease from 4.0594 to 4.0554, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch27.tar
2023-04-16 22:36:24,610 - INFO - epoch complete!
2023-04-16 22:36:24,611 - INFO - evaluating now!
2023-04-16 22:36:24,629 - INFO - Epoch [28/50] train_loss: 4.0554, val_loss: 4.0515, lr: 0.000100, 0.05s
2023-04-16 22:36:24,636 - INFO - Saved model at 28
2023-04-16 22:36:24,636 - INFO - Val loss decrease from 4.0554 to 4.0515, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch28.tar
2023-04-16 22:36:24,670 - INFO - epoch complete!
2023-04-16 22:36:24,670 - INFO - evaluating now!
2023-04-16 22:36:24,690 - INFO - Epoch [29/50] train_loss: 4.0515, val_loss: 4.0475, lr: 0.000100, 0.05s
2023-04-16 22:36:24,698 - INFO - Saved model at 29
2023-04-16 22:36:24,698 - INFO - Val loss decrease from 4.0515 to 4.0475, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch29.tar
2023-04-16 22:36:24,730 - INFO - epoch complete!
2023-04-16 22:36:24,731 - INFO - evaluating now!
2023-04-16 22:36:24,749 - INFO - Epoch [30/50] train_loss: 4.0475, val_loss: 4.0436, lr: 0.000100, 0.05s
2023-04-16 22:36:24,756 - INFO - Saved model at 30
2023-04-16 22:36:24,756 - INFO - Val loss decrease from 4.0475 to 4.0436, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch30.tar
2023-04-16 22:36:24,790 - INFO - epoch complete!
2023-04-16 22:36:24,791 - INFO - evaluating now!
2023-04-16 22:36:24,809 - INFO - Epoch [31/50] train_loss: 4.0436, val_loss: 4.0396, lr: 0.000100, 0.05s
2023-04-16 22:36:24,816 - INFO - Saved model at 31
2023-04-16 22:36:24,816 - INFO - Val loss decrease from 4.0436 to 4.0396, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch31.tar
2023-04-16 22:36:24,850 - INFO - epoch complete!
2023-04-16 22:36:24,851 - INFO - evaluating now!
2023-04-16 22:36:24,869 - INFO - Epoch [32/50] train_loss: 4.0396, val_loss: 4.0356, lr: 0.000100, 0.05s
2023-04-16 22:36:24,876 - INFO - Saved model at 32
2023-04-16 22:36:24,876 - INFO - Val loss decrease from 4.0396 to 4.0356, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch32.tar
2023-04-16 22:36:24,910 - INFO - epoch complete!
2023-04-16 22:36:24,910 - INFO - evaluating now!
2023-04-16 22:36:24,929 - INFO - Epoch [33/50] train_loss: 4.0356, val_loss: 4.0316, lr: 0.000100, 0.05s
2023-04-16 22:36:24,935 - INFO - Saved model at 33
2023-04-16 22:36:24,936 - INFO - Val loss decrease from 4.0356 to 4.0316, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch33.tar
2023-04-16 22:36:24,969 - INFO - epoch complete!
2023-04-16 22:36:24,969 - INFO - evaluating now!
2023-04-16 22:36:24,988 - INFO - Epoch [34/50] train_loss: 4.0316, val_loss: 4.0277, lr: 0.000100, 0.05s
2023-04-16 22:36:24,995 - INFO - Saved model at 34
2023-04-16 22:36:24,995 - INFO - Val loss decrease from 4.0316 to 4.0277, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch34.tar
2023-04-16 22:36:25,030 - INFO - epoch complete!
2023-04-16 22:36:25,030 - INFO - evaluating now!
2023-04-16 22:36:25,047 - INFO - Epoch [35/50] train_loss: 4.0277, val_loss: 4.0238, lr: 0.000100, 0.05s
2023-04-16 22:36:25,053 - INFO - Saved model at 35
2023-04-16 22:36:25,054 - INFO - Val loss decrease from 4.0277 to 4.0238, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch35.tar
2023-04-16 22:36:25,091 - INFO - epoch complete!
2023-04-16 22:36:25,092 - INFO - evaluating now!
2023-04-16 22:36:25,109 - INFO - Epoch [36/50] train_loss: 4.0238, val_loss: 4.0199, lr: 0.000100, 0.06s
2023-04-16 22:36:25,117 - INFO - Saved model at 36
2023-04-16 22:36:25,117 - INFO - Val loss decrease from 4.0238 to 4.0199, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch36.tar
2023-04-16 22:36:25,151 - INFO - epoch complete!
2023-04-16 22:36:25,151 - INFO - evaluating now!
2023-04-16 22:36:25,169 - INFO - Epoch [37/50] train_loss: 4.0199, val_loss: 4.0160, lr: 0.000100, 0.05s
2023-04-16 22:36:25,176 - INFO - Saved model at 37
2023-04-16 22:36:25,176 - INFO - Val loss decrease from 4.0199 to 4.0160, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch37.tar
2023-04-16 22:36:25,210 - INFO - epoch complete!
2023-04-16 22:36:25,210 - INFO - evaluating now!
2023-04-16 22:36:25,227 - INFO - Epoch [38/50] train_loss: 4.0160, val_loss: 4.0121, lr: 0.000100, 0.05s
2023-04-16 22:36:25,234 - INFO - Saved model at 38
2023-04-16 22:36:25,234 - INFO - Val loss decrease from 4.0160 to 4.0121, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch38.tar
2023-04-16 22:36:25,270 - INFO - epoch complete!
2023-04-16 22:36:25,270 - INFO - evaluating now!
2023-04-16 22:36:25,286 - INFO - Epoch [39/50] train_loss: 4.0121, val_loss: 4.0083, lr: 0.000010, 0.05s
2023-04-16 22:36:25,294 - INFO - Saved model at 39
2023-04-16 22:36:25,294 - INFO - Val loss decrease from 4.0121 to 4.0083, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch39.tar
2023-04-16 22:36:25,330 - INFO - epoch complete!
2023-04-16 22:36:25,331 - INFO - evaluating now!
2023-04-16 22:36:25,347 - INFO - Epoch [40/50] train_loss: 4.0083, val_loss: 4.0079, lr: 0.000010, 0.05s
2023-04-16 22:36:25,358 - INFO - Saved model at 40
2023-04-16 22:36:25,359 - INFO - Val loss decrease from 4.0083 to 4.0079, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch40.tar
2023-04-16 22:36:25,394 - INFO - epoch complete!
2023-04-16 22:36:25,395 - INFO - evaluating now!
2023-04-16 22:36:25,413 - INFO - Epoch [41/50] train_loss: 4.0079, val_loss: 4.0075, lr: 0.000010, 0.05s
2023-04-16 22:36:25,420 - INFO - Saved model at 41
2023-04-16 22:36:25,420 - INFO - Val loss decrease from 4.0079 to 4.0075, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch41.tar
2023-04-16 22:36:25,454 - INFO - epoch complete!
2023-04-16 22:36:25,454 - INFO - evaluating now!
2023-04-16 22:36:25,472 - INFO - Epoch [42/50] train_loss: 4.0075, val_loss: 4.0071, lr: 0.000010, 0.05s
2023-04-16 22:36:25,480 - INFO - Saved model at 42
2023-04-16 22:36:25,480 - INFO - Val loss decrease from 4.0075 to 4.0071, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch42.tar
2023-04-16 22:36:25,515 - INFO - epoch complete!
2023-04-16 22:36:25,515 - INFO - evaluating now!
2023-04-16 22:36:25,534 - INFO - Epoch [43/50] train_loss: 4.0071, val_loss: 4.0067, lr: 0.000010, 0.05s
2023-04-16 22:36:25,541 - INFO - Saved model at 43
2023-04-16 22:36:25,541 - INFO - Val loss decrease from 4.0071 to 4.0067, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch43.tar
2023-04-16 22:36:25,575 - INFO - epoch complete!
2023-04-16 22:36:25,575 - INFO - evaluating now!
2023-04-16 22:36:25,593 - INFO - Epoch [44/50] train_loss: 4.0067, val_loss: 4.0063, lr: 0.000010, 0.05s
2023-04-16 22:36:25,599 - INFO - Saved model at 44
2023-04-16 22:36:25,600 - INFO - Val loss decrease from 4.0067 to 4.0063, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch44.tar
2023-04-16 22:36:25,634 - INFO - epoch complete!
2023-04-16 22:36:25,634 - INFO - evaluating now!
2023-04-16 22:36:25,651 - INFO - Epoch [45/50] train_loss: 4.0063, val_loss: 4.0059, lr: 0.000010, 0.05s
2023-04-16 22:36:25,658 - INFO - Saved model at 45
2023-04-16 22:36:25,658 - INFO - Val loss decrease from 4.0063 to 4.0059, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch45.tar
2023-04-16 22:36:25,694 - INFO - epoch complete!
2023-04-16 22:36:25,694 - INFO - evaluating now!
2023-04-16 22:36:25,711 - INFO - Epoch [46/50] train_loss: 4.0059, val_loss: 4.0054, lr: 0.000010, 0.05s
2023-04-16 22:36:25,718 - INFO - Saved model at 46
2023-04-16 22:36:25,718 - INFO - Val loss decrease from 4.0059 to 4.0054, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch46.tar
2023-04-16 22:36:25,753 - INFO - epoch complete!
2023-04-16 22:36:25,753 - INFO - evaluating now!
2023-04-16 22:36:25,769 - INFO - Epoch [47/50] train_loss: 4.0054, val_loss: 4.0050, lr: 0.000010, 0.05s
2023-04-16 22:36:25,776 - INFO - Saved model at 47
2023-04-16 22:36:25,776 - INFO - Val loss decrease from 4.0054 to 4.0050, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch47.tar
2023-04-16 22:36:25,813 - INFO - epoch complete!
2023-04-16 22:36:25,814 - INFO - evaluating now!
2023-04-16 22:36:25,830 - INFO - Epoch [48/50] train_loss: 4.0050, val_loss: 4.0046, lr: 0.000010, 0.05s
2023-04-16 22:36:25,837 - INFO - Saved model at 48
2023-04-16 22:36:25,837 - INFO - Val loss decrease from 4.0050 to 4.0046, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch48.tar
2023-04-16 22:36:25,874 - INFO - epoch complete!
2023-04-16 22:36:25,874 - INFO - evaluating now!
2023-04-16 22:36:25,890 - INFO - Epoch [49/50] train_loss: 4.0046, val_loss: 4.0042, lr: 0.000010, 0.05s
2023-04-16 22:36:25,898 - INFO - Saved model at 49
2023-04-16 22:36:25,898 - INFO - Val loss decrease from 4.0046 to 4.0042, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch49.tar
2023-04-16 22:36:25,898 - INFO - Trained totally 50 epochs, average train time is 0.035s, average eval time is 0.017s
2023-04-16 22:36:25,904 - INFO - Loaded model at 49
2023-04-16 22:36:25,904 - INFO - Saved model at ./libcity/cache/50001/model_cache/GRU_Xiongan.m
2023-04-16 22:36:25,910 - INFO - Start evaluating ...
2023-04-16 22:36:26,034 - INFO - Note that you select the single mode to evaluate!
2023-04-16 22:36:26,039 - INFO - Evaluate result is saved at ./libcity/cache/50001/evaluate_cache/2023_04_16_22_36_26_RNN_Xiongan.csv
2023-04-16 22:36:26,051 - INFO - 
         MAE      MAPE        MSE      RMSE  masked_MAE  masked_MAPE  masked_MSE  masked_RMSE        R2      EVAR
1   2.250899  0.037647  12.368184  3.516843    2.250899     0.037647   12.368184     3.516843  0.593109  0.594523
2   3.344276  0.055966  20.481033  4.525598    3.344276     0.055966   20.481033     4.525598  0.373281  0.374910
3   4.026163  0.069235  27.212032  5.216516    4.026163     0.069235   27.212032     5.216516  0.200841  0.208777
4   4.127725  0.069481  26.735954  5.170682    4.127725     0.069481   26.735954     5.170682  0.196767  0.196795
5   4.303253  0.071719  28.313322  5.321026    4.303253     0.071719   28.313322     5.321026  0.109807  0.115023
6   4.137739  0.069749  27.397322  5.234245    4.137739     0.069749   27.397322     5.234245  0.174289  0.174582
7   4.298354  0.073181  28.927374  5.378417    4.298354     0.073181   28.927374     5.378417  0.090398  0.091811
8   4.452670  0.075511  30.248686  5.499880    4.452670     0.075511   30.248686     5.499880  0.112592  0.113023
9   4.334240  0.073378  29.229095  5.406394    4.334240     0.073378   29.229095     5.406394  0.129242  0.129243
10  4.437533  0.074155  31.576395  5.619288    4.437533     0.074155   31.576395     5.619288  0.076077  0.077923
11  4.457975  0.075895  32.282181  5.681741    4.457975     0.075895   32.282181     5.681741  0.036337  0.037675
12  3.879151  0.065489  24.454947  4.945194    3.879151     0.065489   24.454947     4.945194  0.249036  0.249670
