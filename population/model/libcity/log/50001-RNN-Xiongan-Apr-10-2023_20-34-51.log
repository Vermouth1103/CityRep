2023-04-10 20:34:51,178 - INFO - Log directory: ./libcity/log
2023-04-10 20:34:51,179 - INFO - Begin pipeline, task=traffic_state_pred, model_name=GRU, dataset_name=Xiongan, exp_id=50001
2023-04-10 20:34:51,179 - INFO - {'task': 'traffic_state_pred', 'model': 'RNN', 'dataset': 'Xiongan', 'saved_model': True, 'train': True, 'exp_id': '50001', 'seed': 0, 'dataset_class': 'TrafficStatePointDataset', 'executor': 'TrafficStateExecutor', 'evaluator': 'TrafficStateEvaluator', 'rnn_type': 'GRU', 'hidden_size': 64, 'num_layers': 1, 'dropout': 0, 'bidirectional': False, 'teacher_forcing_ratio': 0, 'scaler': 'standard', 'load_external': True, 'normal_external': False, 'ext_scaler': 'none', 'add_time_in_day': True, 'add_day_in_week': False, 'max_epoch': 100, 'learner': 'adam', 'learning_rate': 0.01, 'lr_decay': True, 'lr_scheduler': 'multisteplr', 'lr_decay_ratio': 0.1, 'steps': [5, 20, 40, 70], 'clip_grad_norm': True, 'max_grad_norm': 5, 'use_early_stop': True, 'patience': 50, 'batch_size': 64, 'cache_dataset': True, 'num_workers': 0, 'pad_with_last_sample': True, 'train_rate': 0.7, 'eval_rate': 0.1, 'input_window': 12, 'output_window': 12, 'gpu': True, 'gpu_id': 0, 'train_loss': 'none', 'epoch': 0, 'weight_decay': 0, 'lr_epsilon': 1e-08, 'lr_beta1': 0.9, 'lr_beta2': 0.999, 'lr_alpha': 0.99, 'lr_momentum': 0, 'step_size': 10, 'lr_T_max': 30, 'lr_eta_min': 0, 'lr_patience': 10, 'lr_threshold': 0.0001, 'log_level': 'INFO', 'log_every': 1, 'load_best_epoch': True, 'hyper_tune': False, 'metrics': ['MAE', 'MAPE', 'MSE', 'RMSE', 'masked_MAE', 'masked_MAPE', 'masked_MSE', 'masked_RMSE', 'R2', 'EVAR'], 'evaluator_mode': 'single', 'save_mode': ['csv'], 'geo': {'including_types': ['Point'], 'Point': {}}, 'rel': {'including_types': ['geo'], 'geo': {'cost': 'num'}}, 'dyna': {'including_types': ['state'], 'state': {'entity_id': 'geo_id', 'traffic_speed': 'num'}}, 'data_col': ['traffic_speed'], 'weight_col': 'cost', 'data_files': ['Xiongan'], 'geo_file': 'Xiongan', 'rel_file': 'Xiongan', 'output_dim': 1, 'time_intervals': 300, 'init_weight_inf_or_zero': 'inf', 'set_weight_link_or_dist': 'dist', 'calculate_weight_adj': True, 'weight_adj_epsilon': 0.1, 'device': device(type='cuda', index=0)}
2023-04-10 20:34:51,235 - INFO - Loaded file Xiongan.geo, num_nodes=487
2023-04-10 20:34:51,238 - INFO - set_weight_link_or_dist: dist
2023-04-10 20:34:51,238 - INFO - init_weight_inf_or_zero: inf
2023-04-10 20:34:51,241 - INFO - Loaded file Xiongan.rel, shape=(487, 487)
2023-04-10 20:34:51,242 - INFO - Start Calculate the weight by Gauss kernel!
2023-04-10 20:34:51,244 - INFO - Loading ./libcity/cache/dataset_cache/point_based_Xiongan_12_12_0.7_0.1_standard_64_True_True_False_True.npz
2023-04-10 20:34:51,313 - INFO - train	x: (26, 12, 487, 2), y: (26, 12, 487, 2)
2023-04-10 20:34:51,313 - INFO - eval	x: (4, 12, 487, 2), y: (4, 12, 487, 2)
2023-04-10 20:34:51,313 - INFO - test	x: (7, 12, 487, 2), y: (7, 12, 487, 2)
2023-04-10 20:34:51,314 - INFO - StandardScaler mean: 59.92392878005366, std: 5.807862904711059
2023-04-10 20:34:51,314 - INFO - NoneScaler
2023-04-10 20:34:51,728 - INFO - You select rnn_type GRU in RNN!
2023-04-10 20:34:56,657 - INFO - RNN(
  (rnn): GRU(974, 64)
  (fc): Linear(in_features=64, out_features=487, bias=True)
)
2023-04-10 20:34:56,658 - INFO - rnn.weight_ih_l0	torch.Size([192, 974])	cuda:0	True
2023-04-10 20:34:56,658 - INFO - rnn.weight_hh_l0	torch.Size([192, 64])	cuda:0	True
2023-04-10 20:34:56,658 - INFO - rnn.bias_ih_l0	torch.Size([192])	cuda:0	True
2023-04-10 20:34:56,658 - INFO - rnn.bias_hh_l0	torch.Size([192])	cuda:0	True
2023-04-10 20:34:56,658 - INFO - fc.weight	torch.Size([487, 64])	cuda:0	True
2023-04-10 20:34:56,658 - INFO - fc.bias	torch.Size([487])	cuda:0	True
2023-04-10 20:34:56,658 - INFO - Total parameter numbers: 231335
2023-04-10 20:34:56,658 - INFO - You select `adam` optimizer.
2023-04-10 20:34:56,659 - INFO - You select `multisteplr` lr_scheduler.
2023-04-10 20:34:56,660 - WARNING - Received none train loss func and will use the loss func defined in the model.
2023-04-10 20:34:56,660 - INFO - Start training ...
2023-04-10 20:34:56,660 - INFO - num_batches:1
2023-04-10 20:34:56,732 - INFO - epoch complete!
2023-04-10 20:34:56,732 - INFO - evaluating now!
2023-04-10 20:34:56,757 - INFO - Epoch [0/100] train_loss: 5.0072, val_loss: 5.0799, lr: 0.010000, 0.10s
2023-04-10 20:34:56,765 - INFO - Saved model at 0
2023-04-10 20:34:56,766 - INFO - Val loss decrease from inf to 5.0799, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch0.tar
2023-04-10 20:34:56,806 - INFO - epoch complete!
2023-04-10 20:34:56,808 - INFO - evaluating now!
2023-04-10 20:34:56,841 - INFO - Epoch [1/100] train_loss: 5.0799, val_loss: 5.0446, lr: 0.010000, 0.07s
2023-04-10 20:34:56,853 - INFO - Saved model at 1
2023-04-10 20:34:56,854 - INFO - Val loss decrease from 5.0799 to 5.0446, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch1.tar
2023-04-10 20:34:56,899 - INFO - epoch complete!
2023-04-10 20:34:56,900 - INFO - evaluating now!
2023-04-10 20:34:56,928 - INFO - Epoch [2/100] train_loss: 5.0446, val_loss: 4.8182, lr: 0.010000, 0.07s
2023-04-10 20:34:56,937 - INFO - Saved model at 2
2023-04-10 20:34:56,937 - INFO - Val loss decrease from 5.0446 to 4.8182, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch2.tar
2023-04-10 20:34:56,989 - INFO - epoch complete!
2023-04-10 20:34:56,990 - INFO - evaluating now!
2023-04-10 20:34:57,018 - INFO - Epoch [3/100] train_loss: 4.8182, val_loss: 4.6643, lr: 0.010000, 0.08s
2023-04-10 20:34:57,045 - INFO - Saved model at 3
2023-04-10 20:34:57,045 - INFO - Val loss decrease from 4.8182 to 4.6643, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch3.tar
2023-04-10 20:34:57,093 - INFO - epoch complete!
2023-04-10 20:34:57,093 - INFO - evaluating now!
2023-04-10 20:34:57,111 - INFO - Epoch [4/100] train_loss: 4.6643, val_loss: 4.5551, lr: 0.001000, 0.07s
2023-04-10 20:34:57,126 - INFO - Saved model at 4
2023-04-10 20:34:57,127 - INFO - Val loss decrease from 4.6643 to 4.5551, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch4.tar
2023-04-10 20:34:57,169 - INFO - epoch complete!
2023-04-10 20:34:57,169 - INFO - evaluating now!
2023-04-10 20:34:57,193 - INFO - Epoch [5/100] train_loss: 4.5551, val_loss: 4.5161, lr: 0.001000, 0.07s
2023-04-10 20:34:57,201 - INFO - Saved model at 5
2023-04-10 20:34:57,201 - INFO - Val loss decrease from 4.5551 to 4.5161, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch5.tar
2023-04-10 20:34:57,243 - INFO - epoch complete!
2023-04-10 20:34:57,244 - INFO - evaluating now!
2023-04-10 20:34:57,273 - INFO - Epoch [6/100] train_loss: 4.5161, val_loss: 4.4734, lr: 0.001000, 0.07s
2023-04-10 20:34:57,282 - INFO - Saved model at 6
2023-04-10 20:34:57,283 - INFO - Val loss decrease from 4.5161 to 4.4734, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch6.tar
2023-04-10 20:34:57,323 - INFO - epoch complete!
2023-04-10 20:34:57,324 - INFO - evaluating now!
2023-04-10 20:34:57,346 - INFO - Epoch [7/100] train_loss: 4.4734, val_loss: 4.4344, lr: 0.001000, 0.06s
2023-04-10 20:34:57,355 - INFO - Saved model at 7
2023-04-10 20:34:57,355 - INFO - Val loss decrease from 4.4734 to 4.4344, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch7.tar
2023-04-10 20:34:57,393 - INFO - epoch complete!
2023-04-10 20:34:57,394 - INFO - evaluating now!
2023-04-10 20:34:57,412 - INFO - Epoch [8/100] train_loss: 4.4344, val_loss: 4.3997, lr: 0.001000, 0.06s
2023-04-10 20:34:57,418 - INFO - Saved model at 8
2023-04-10 20:34:57,418 - INFO - Val loss decrease from 4.4344 to 4.3997, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch8.tar
2023-04-10 20:34:57,467 - INFO - epoch complete!
2023-04-10 20:34:57,467 - INFO - evaluating now!
2023-04-10 20:34:57,494 - INFO - Epoch [9/100] train_loss: 4.3997, val_loss: 4.3682, lr: 0.001000, 0.08s
2023-04-10 20:34:57,503 - INFO - Saved model at 9
2023-04-10 20:34:57,503 - INFO - Val loss decrease from 4.3997 to 4.3682, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch9.tar
2023-04-10 20:34:57,538 - INFO - epoch complete!
2023-04-10 20:34:57,539 - INFO - evaluating now!
2023-04-10 20:34:57,557 - INFO - Epoch [10/100] train_loss: 4.3682, val_loss: 4.3398, lr: 0.001000, 0.05s
2023-04-10 20:34:57,564 - INFO - Saved model at 10
2023-04-10 20:34:57,564 - INFO - Val loss decrease from 4.3682 to 4.3398, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch10.tar
2023-04-10 20:34:57,603 - INFO - epoch complete!
2023-04-10 20:34:57,603 - INFO - evaluating now!
2023-04-10 20:34:57,626 - INFO - Epoch [11/100] train_loss: 4.3398, val_loss: 4.3106, lr: 0.001000, 0.06s
2023-04-10 20:34:57,634 - INFO - Saved model at 11
2023-04-10 20:34:57,635 - INFO - Val loss decrease from 4.3398 to 4.3106, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch11.tar
2023-04-10 20:34:57,672 - INFO - epoch complete!
2023-04-10 20:34:57,673 - INFO - evaluating now!
2023-04-10 20:34:57,695 - INFO - Epoch [12/100] train_loss: 4.3106, val_loss: 4.2808, lr: 0.001000, 0.06s
2023-04-10 20:34:57,704 - INFO - Saved model at 12
2023-04-10 20:34:57,704 - INFO - Val loss decrease from 4.3106 to 4.2808, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch12.tar
2023-04-10 20:34:57,757 - INFO - epoch complete!
2023-04-10 20:34:57,757 - INFO - evaluating now!
2023-04-10 20:34:57,785 - INFO - Epoch [13/100] train_loss: 4.2808, val_loss: 4.2534, lr: 0.001000, 0.08s
2023-04-10 20:34:57,794 - INFO - Saved model at 13
2023-04-10 20:34:57,795 - INFO - Val loss decrease from 4.2808 to 4.2534, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch13.tar
2023-04-10 20:34:57,833 - INFO - epoch complete!
2023-04-10 20:34:57,833 - INFO - evaluating now!
2023-04-10 20:34:57,857 - INFO - Epoch [14/100] train_loss: 4.2534, val_loss: 4.2257, lr: 0.001000, 0.06s
2023-04-10 20:34:57,865 - INFO - Saved model at 14
2023-04-10 20:34:57,865 - INFO - Val loss decrease from 4.2534 to 4.2257, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch14.tar
2023-04-10 20:34:57,909 - INFO - epoch complete!
2023-04-10 20:34:57,909 - INFO - evaluating now!
2023-04-10 20:34:57,941 - INFO - Epoch [15/100] train_loss: 4.2257, val_loss: 4.1969, lr: 0.001000, 0.08s
2023-04-10 20:34:57,950 - INFO - Saved model at 15
2023-04-10 20:34:57,950 - INFO - Val loss decrease from 4.2257 to 4.1969, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch15.tar
2023-04-10 20:34:58,002 - INFO - epoch complete!
2023-04-10 20:34:58,003 - INFO - evaluating now!
2023-04-10 20:34:58,022 - INFO - Epoch [16/100] train_loss: 4.1969, val_loss: 4.1688, lr: 0.001000, 0.07s
2023-04-10 20:34:58,033 - INFO - Saved model at 16
2023-04-10 20:34:58,034 - INFO - Val loss decrease from 4.1969 to 4.1688, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch16.tar
2023-04-10 20:34:58,080 - INFO - epoch complete!
2023-04-10 20:34:58,081 - INFO - evaluating now!
2023-04-10 20:34:58,106 - INFO - Epoch [17/100] train_loss: 4.1688, val_loss: 4.1413, lr: 0.001000, 0.07s
2023-04-10 20:34:58,113 - INFO - Saved model at 17
2023-04-10 20:34:58,113 - INFO - Val loss decrease from 4.1688 to 4.1413, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch17.tar
2023-04-10 20:34:58,156 - INFO - epoch complete!
2023-04-10 20:34:58,156 - INFO - evaluating now!
2023-04-10 20:34:58,191 - INFO - Epoch [18/100] train_loss: 4.1413, val_loss: 4.1130, lr: 0.001000, 0.08s
2023-04-10 20:34:58,200 - INFO - Saved model at 18
2023-04-10 20:34:58,200 - INFO - Val loss decrease from 4.1413 to 4.1130, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch18.tar
2023-04-10 20:34:58,241 - INFO - epoch complete!
2023-04-10 20:34:58,243 - INFO - evaluating now!
2023-04-10 20:34:58,268 - INFO - Epoch [19/100] train_loss: 4.1130, val_loss: 4.0849, lr: 0.000100, 0.07s
2023-04-10 20:34:58,280 - INFO - Saved model at 19
2023-04-10 20:34:58,280 - INFO - Val loss decrease from 4.1130 to 4.0849, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch19.tar
2023-04-10 20:34:58,321 - INFO - epoch complete!
2023-04-10 20:34:58,321 - INFO - evaluating now!
2023-04-10 20:34:58,343 - INFO - Epoch [20/100] train_loss: 4.0849, val_loss: 4.0819, lr: 0.000100, 0.06s
2023-04-10 20:34:58,352 - INFO - Saved model at 20
2023-04-10 20:34:58,352 - INFO - Val loss decrease from 4.0849 to 4.0819, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch20.tar
2023-04-10 20:34:58,410 - INFO - epoch complete!
2023-04-10 20:34:58,411 - INFO - evaluating now!
2023-04-10 20:34:58,431 - INFO - Epoch [21/100] train_loss: 4.0819, val_loss: 4.0786, lr: 0.000100, 0.08s
2023-04-10 20:34:58,448 - INFO - Saved model at 21
2023-04-10 20:34:58,448 - INFO - Val loss decrease from 4.0819 to 4.0786, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch21.tar
2023-04-10 20:34:58,493 - INFO - epoch complete!
2023-04-10 20:34:58,494 - INFO - evaluating now!
2023-04-10 20:34:58,524 - INFO - Epoch [22/100] train_loss: 4.0786, val_loss: 4.0749, lr: 0.000100, 0.07s
2023-04-10 20:34:58,533 - INFO - Saved model at 22
2023-04-10 20:34:58,533 - INFO - Val loss decrease from 4.0786 to 4.0749, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch22.tar
2023-04-10 20:34:58,584 - INFO - epoch complete!
2023-04-10 20:34:58,585 - INFO - evaluating now!
2023-04-10 20:34:58,609 - INFO - Epoch [23/100] train_loss: 4.0749, val_loss: 4.0711, lr: 0.000100, 0.08s
2023-04-10 20:34:58,625 - INFO - Saved model at 23
2023-04-10 20:34:58,625 - INFO - Val loss decrease from 4.0749 to 4.0711, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch23.tar
2023-04-10 20:34:58,658 - INFO - epoch complete!
2023-04-10 20:34:58,659 - INFO - evaluating now!
2023-04-10 20:34:58,677 - INFO - Epoch [24/100] train_loss: 4.0711, val_loss: 4.0673, lr: 0.000100, 0.05s
2023-04-10 20:34:58,690 - INFO - Saved model at 24
2023-04-10 20:34:58,690 - INFO - Val loss decrease from 4.0711 to 4.0673, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch24.tar
2023-04-10 20:34:58,734 - INFO - epoch complete!
2023-04-10 20:34:58,734 - INFO - evaluating now!
2023-04-10 20:34:58,752 - INFO - Epoch [25/100] train_loss: 4.0673, val_loss: 4.0634, lr: 0.000100, 0.06s
2023-04-10 20:34:58,760 - INFO - Saved model at 25
2023-04-10 20:34:58,760 - INFO - Val loss decrease from 4.0673 to 4.0634, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch25.tar
2023-04-10 20:34:58,799 - INFO - epoch complete!
2023-04-10 20:34:58,799 - INFO - evaluating now!
2023-04-10 20:34:58,819 - INFO - Epoch [26/100] train_loss: 4.0634, val_loss: 4.0594, lr: 0.000100, 0.06s
2023-04-10 20:34:58,825 - INFO - Saved model at 26
2023-04-10 20:34:58,826 - INFO - Val loss decrease from 4.0634 to 4.0594, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch26.tar
2023-04-10 20:34:58,865 - INFO - epoch complete!
2023-04-10 20:34:58,865 - INFO - evaluating now!
2023-04-10 20:34:58,890 - INFO - Epoch [27/100] train_loss: 4.0594, val_loss: 4.0554, lr: 0.000100, 0.06s
2023-04-10 20:34:58,908 - INFO - Saved model at 27
2023-04-10 20:34:58,908 - INFO - Val loss decrease from 4.0594 to 4.0554, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch27.tar
2023-04-10 20:34:58,951 - INFO - epoch complete!
2023-04-10 20:34:58,952 - INFO - evaluating now!
2023-04-10 20:34:58,976 - INFO - Epoch [28/100] train_loss: 4.0554, val_loss: 4.0515, lr: 0.000100, 0.07s
2023-04-10 20:34:58,986 - INFO - Saved model at 28
2023-04-10 20:34:58,986 - INFO - Val loss decrease from 4.0554 to 4.0515, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch28.tar
2023-04-10 20:34:59,040 - INFO - epoch complete!
2023-04-10 20:34:59,040 - INFO - evaluating now!
2023-04-10 20:34:59,077 - INFO - Epoch [29/100] train_loss: 4.0515, val_loss: 4.0475, lr: 0.000100, 0.09s
2023-04-10 20:34:59,086 - INFO - Saved model at 29
2023-04-10 20:34:59,086 - INFO - Val loss decrease from 4.0515 to 4.0475, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch29.tar
2023-04-10 20:34:59,132 - INFO - epoch complete!
2023-04-10 20:34:59,133 - INFO - evaluating now!
2023-04-10 20:34:59,156 - INFO - Epoch [30/100] train_loss: 4.0475, val_loss: 4.0436, lr: 0.000100, 0.07s
2023-04-10 20:34:59,163 - INFO - Saved model at 30
2023-04-10 20:34:59,163 - INFO - Val loss decrease from 4.0475 to 4.0436, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch30.tar
2023-04-10 20:34:59,218 - INFO - epoch complete!
2023-04-10 20:34:59,218 - INFO - evaluating now!
2023-04-10 20:34:59,236 - INFO - Epoch [31/100] train_loss: 4.0436, val_loss: 4.0396, lr: 0.000100, 0.07s
2023-04-10 20:34:59,245 - INFO - Saved model at 31
2023-04-10 20:34:59,245 - INFO - Val loss decrease from 4.0436 to 4.0396, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch31.tar
2023-04-10 20:34:59,291 - INFO - epoch complete!
2023-04-10 20:34:59,291 - INFO - evaluating now!
2023-04-10 20:34:59,316 - INFO - Epoch [32/100] train_loss: 4.0396, val_loss: 4.0356, lr: 0.000100, 0.07s
2023-04-10 20:34:59,325 - INFO - Saved model at 32
2023-04-10 20:34:59,325 - INFO - Val loss decrease from 4.0396 to 4.0356, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch32.tar
2023-04-10 20:34:59,378 - INFO - epoch complete!
2023-04-10 20:34:59,378 - INFO - evaluating now!
2023-04-10 20:34:59,399 - INFO - Epoch [33/100] train_loss: 4.0356, val_loss: 4.0316, lr: 0.000100, 0.07s
2023-04-10 20:34:59,407 - INFO - Saved model at 33
2023-04-10 20:34:59,407 - INFO - Val loss decrease from 4.0356 to 4.0316, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch33.tar
2023-04-10 20:34:59,449 - INFO - epoch complete!
2023-04-10 20:34:59,450 - INFO - evaluating now!
2023-04-10 20:34:59,475 - INFO - Epoch [34/100] train_loss: 4.0316, val_loss: 4.0277, lr: 0.000100, 0.07s
2023-04-10 20:34:59,484 - INFO - Saved model at 34
2023-04-10 20:34:59,484 - INFO - Val loss decrease from 4.0316 to 4.0277, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch34.tar
2023-04-10 20:34:59,528 - INFO - epoch complete!
2023-04-10 20:34:59,529 - INFO - evaluating now!
2023-04-10 20:34:59,554 - INFO - Epoch [35/100] train_loss: 4.0277, val_loss: 4.0237, lr: 0.000100, 0.07s
2023-04-10 20:34:59,561 - INFO - Saved model at 35
2023-04-10 20:34:59,561 - INFO - Val loss decrease from 4.0277 to 4.0237, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch35.tar
2023-04-10 20:34:59,599 - INFO - epoch complete!
2023-04-10 20:34:59,600 - INFO - evaluating now!
2023-04-10 20:34:59,637 - INFO - Epoch [36/100] train_loss: 4.0237, val_loss: 4.0199, lr: 0.000100, 0.08s
2023-04-10 20:34:59,655 - INFO - Saved model at 36
2023-04-10 20:34:59,655 - INFO - Val loss decrease from 4.0237 to 4.0199, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch36.tar
2023-04-10 20:34:59,705 - INFO - epoch complete!
2023-04-10 20:34:59,706 - INFO - evaluating now!
2023-04-10 20:34:59,725 - INFO - Epoch [37/100] train_loss: 4.0199, val_loss: 4.0160, lr: 0.000100, 0.07s
2023-04-10 20:34:59,734 - INFO - Saved model at 37
2023-04-10 20:34:59,734 - INFO - Val loss decrease from 4.0199 to 4.0160, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch37.tar
2023-04-10 20:34:59,773 - INFO - epoch complete!
2023-04-10 20:34:59,773 - INFO - evaluating now!
2023-04-10 20:34:59,802 - INFO - Epoch [38/100] train_loss: 4.0160, val_loss: 4.0122, lr: 0.000100, 0.07s
2023-04-10 20:34:59,810 - INFO - Saved model at 38
2023-04-10 20:34:59,810 - INFO - Val loss decrease from 4.0160 to 4.0122, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch38.tar
2023-04-10 20:34:59,844 - INFO - epoch complete!
2023-04-10 20:34:59,845 - INFO - evaluating now!
2023-04-10 20:34:59,870 - INFO - Epoch [39/100] train_loss: 4.0122, val_loss: 4.0083, lr: 0.000010, 0.06s
2023-04-10 20:34:59,879 - INFO - Saved model at 39
2023-04-10 20:34:59,879 - INFO - Val loss decrease from 4.0122 to 4.0083, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch39.tar
2023-04-10 20:34:59,928 - INFO - epoch complete!
2023-04-10 20:34:59,929 - INFO - evaluating now!
2023-04-10 20:34:59,948 - INFO - Epoch [40/100] train_loss: 4.0083, val_loss: 4.0079, lr: 0.000010, 0.07s
2023-04-10 20:34:59,955 - INFO - Saved model at 40
2023-04-10 20:34:59,955 - INFO - Val loss decrease from 4.0083 to 4.0079, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch40.tar
2023-04-10 20:34:59,991 - INFO - epoch complete!
2023-04-10 20:34:59,991 - INFO - evaluating now!
2023-04-10 20:35:00,011 - INFO - Epoch [41/100] train_loss: 4.0079, val_loss: 4.0075, lr: 0.000010, 0.06s
2023-04-10 20:35:00,021 - INFO - Saved model at 41
2023-04-10 20:35:00,022 - INFO - Val loss decrease from 4.0079 to 4.0075, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch41.tar
2023-04-10 20:35:00,060 - INFO - epoch complete!
2023-04-10 20:35:00,061 - INFO - evaluating now!
2023-04-10 20:35:00,083 - INFO - Epoch [42/100] train_loss: 4.0075, val_loss: 4.0071, lr: 0.000010, 0.06s
2023-04-10 20:35:00,092 - INFO - Saved model at 42
2023-04-10 20:35:00,092 - INFO - Val loss decrease from 4.0075 to 4.0071, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch42.tar
2023-04-10 20:35:00,127 - INFO - epoch complete!
2023-04-10 20:35:00,127 - INFO - evaluating now!
2023-04-10 20:35:00,148 - INFO - Epoch [43/100] train_loss: 4.0071, val_loss: 4.0067, lr: 0.000010, 0.06s
2023-04-10 20:35:00,156 - INFO - Saved model at 43
2023-04-10 20:35:00,157 - INFO - Val loss decrease from 4.0071 to 4.0067, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch43.tar
2023-04-10 20:35:00,219 - INFO - epoch complete!
2023-04-10 20:35:00,219 - INFO - evaluating now!
2023-04-10 20:35:00,246 - INFO - Epoch [44/100] train_loss: 4.0067, val_loss: 4.0063, lr: 0.000010, 0.09s
2023-04-10 20:35:00,254 - INFO - Saved model at 44
2023-04-10 20:35:00,254 - INFO - Val loss decrease from 4.0067 to 4.0063, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch44.tar
2023-04-10 20:35:00,299 - INFO - epoch complete!
2023-04-10 20:35:00,300 - INFO - evaluating now!
2023-04-10 20:35:00,318 - INFO - Epoch [45/100] train_loss: 4.0063, val_loss: 4.0059, lr: 0.000010, 0.06s
2023-04-10 20:35:00,328 - INFO - Saved model at 45
2023-04-10 20:35:00,329 - INFO - Val loss decrease from 4.0063 to 4.0059, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch45.tar
2023-04-10 20:35:00,391 - INFO - epoch complete!
2023-04-10 20:35:00,391 - INFO - evaluating now!
2023-04-10 20:35:00,423 - INFO - Epoch [46/100] train_loss: 4.0059, val_loss: 4.0054, lr: 0.000010, 0.09s
2023-04-10 20:35:00,429 - INFO - Saved model at 46
2023-04-10 20:35:00,430 - INFO - Val loss decrease from 4.0059 to 4.0054, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch46.tar
2023-04-10 20:35:00,479 - INFO - epoch complete!
2023-04-10 20:35:00,479 - INFO - evaluating now!
2023-04-10 20:35:00,509 - INFO - Epoch [47/100] train_loss: 4.0054, val_loss: 4.0050, lr: 0.000010, 0.08s
2023-04-10 20:35:00,524 - INFO - Saved model at 47
2023-04-10 20:35:00,525 - INFO - Val loss decrease from 4.0054 to 4.0050, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch47.tar
2023-04-10 20:35:00,563 - INFO - epoch complete!
2023-04-10 20:35:00,564 - INFO - evaluating now!
2023-04-10 20:35:00,594 - INFO - Epoch [48/100] train_loss: 4.0050, val_loss: 4.0046, lr: 0.000010, 0.07s
2023-04-10 20:35:00,602 - INFO - Saved model at 48
2023-04-10 20:35:00,603 - INFO - Val loss decrease from 4.0050 to 4.0046, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch48.tar
2023-04-10 20:35:00,635 - INFO - epoch complete!
2023-04-10 20:35:00,637 - INFO - evaluating now!
2023-04-10 20:35:00,656 - INFO - Epoch [49/100] train_loss: 4.0046, val_loss: 4.0042, lr: 0.000010, 0.05s
2023-04-10 20:35:00,673 - INFO - Saved model at 49
2023-04-10 20:35:00,674 - INFO - Val loss decrease from 4.0046 to 4.0042, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch49.tar
2023-04-10 20:35:00,707 - INFO - epoch complete!
2023-04-10 20:35:00,708 - INFO - evaluating now!
2023-04-10 20:35:00,727 - INFO - Epoch [50/100] train_loss: 4.0042, val_loss: 4.0037, lr: 0.000010, 0.05s
2023-04-10 20:35:00,734 - INFO - Saved model at 50
2023-04-10 20:35:00,735 - INFO - Val loss decrease from 4.0042 to 4.0037, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch50.tar
2023-04-10 20:35:00,768 - INFO - epoch complete!
2023-04-10 20:35:00,768 - INFO - evaluating now!
2023-04-10 20:35:00,795 - INFO - Epoch [51/100] train_loss: 4.0037, val_loss: 4.0033, lr: 0.000010, 0.06s
2023-04-10 20:35:00,802 - INFO - Saved model at 51
2023-04-10 20:35:00,803 - INFO - Val loss decrease from 4.0037 to 4.0033, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch51.tar
2023-04-10 20:35:00,836 - INFO - epoch complete!
2023-04-10 20:35:00,837 - INFO - evaluating now!
2023-04-10 20:35:00,869 - INFO - Epoch [52/100] train_loss: 4.0033, val_loss: 4.0029, lr: 0.000010, 0.07s
2023-04-10 20:35:00,877 - INFO - Saved model at 52
2023-04-10 20:35:00,877 - INFO - Val loss decrease from 4.0033 to 4.0029, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch52.tar
2023-04-10 20:35:00,921 - INFO - epoch complete!
2023-04-10 20:35:00,922 - INFO - evaluating now!
2023-04-10 20:35:00,940 - INFO - Epoch [53/100] train_loss: 4.0029, val_loss: 4.0025, lr: 0.000010, 0.06s
2023-04-10 20:35:00,948 - INFO - Saved model at 53
2023-04-10 20:35:00,949 - INFO - Val loss decrease from 4.0029 to 4.0025, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch53.tar
2023-04-10 20:35:00,993 - INFO - epoch complete!
2023-04-10 20:35:00,993 - INFO - evaluating now!
2023-04-10 20:35:01,015 - INFO - Epoch [54/100] train_loss: 4.0025, val_loss: 4.0020, lr: 0.000010, 0.07s
2023-04-10 20:35:01,022 - INFO - Saved model at 54
2023-04-10 20:35:01,022 - INFO - Val loss decrease from 4.0025 to 4.0020, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch54.tar
2023-04-10 20:35:01,075 - INFO - epoch complete!
2023-04-10 20:35:01,076 - INFO - evaluating now!
2023-04-10 20:35:01,103 - INFO - Epoch [55/100] train_loss: 4.0020, val_loss: 4.0016, lr: 0.000010, 0.08s
2023-04-10 20:35:01,117 - INFO - Saved model at 55
2023-04-10 20:35:01,118 - INFO - Val loss decrease from 4.0020 to 4.0016, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch55.tar
2023-04-10 20:35:01,168 - INFO - epoch complete!
2023-04-10 20:35:01,169 - INFO - evaluating now!
2023-04-10 20:35:01,196 - INFO - Epoch [56/100] train_loss: 4.0016, val_loss: 4.0012, lr: 0.000010, 0.08s
2023-04-10 20:35:01,208 - INFO - Saved model at 56
2023-04-10 20:35:01,208 - INFO - Val loss decrease from 4.0016 to 4.0012, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch56.tar
2023-04-10 20:35:01,262 - INFO - epoch complete!
2023-04-10 20:35:01,262 - INFO - evaluating now!
2023-04-10 20:35:01,284 - INFO - Epoch [57/100] train_loss: 4.0012, val_loss: 4.0007, lr: 0.000010, 0.08s
2023-04-10 20:35:01,290 - INFO - Saved model at 57
2023-04-10 20:35:01,291 - INFO - Val loss decrease from 4.0012 to 4.0007, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch57.tar
2023-04-10 20:35:01,333 - INFO - epoch complete!
2023-04-10 20:35:01,336 - INFO - evaluating now!
2023-04-10 20:35:01,353 - INFO - Epoch [58/100] train_loss: 4.0007, val_loss: 4.0003, lr: 0.000010, 0.06s
2023-04-10 20:35:01,365 - INFO - Saved model at 58
2023-04-10 20:35:01,365 - INFO - Val loss decrease from 4.0007 to 4.0003, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch58.tar
2023-04-10 20:35:01,402 - INFO - epoch complete!
2023-04-10 20:35:01,403 - INFO - evaluating now!
2023-04-10 20:35:01,422 - INFO - Epoch [59/100] train_loss: 4.0003, val_loss: 3.9999, lr: 0.000010, 0.06s
2023-04-10 20:35:01,429 - INFO - Saved model at 59
2023-04-10 20:35:01,429 - INFO - Val loss decrease from 4.0003 to 3.9999, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch59.tar
2023-04-10 20:35:01,462 - INFO - epoch complete!
2023-04-10 20:35:01,462 - INFO - evaluating now!
2023-04-10 20:35:01,481 - INFO - Epoch [60/100] train_loss: 3.9999, val_loss: 3.9995, lr: 0.000010, 0.05s
2023-04-10 20:35:01,489 - INFO - Saved model at 60
2023-04-10 20:35:01,490 - INFO - Val loss decrease from 3.9999 to 3.9995, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch60.tar
2023-04-10 20:35:01,545 - INFO - epoch complete!
2023-04-10 20:35:01,546 - INFO - evaluating now!
2023-04-10 20:35:01,570 - INFO - Epoch [61/100] train_loss: 3.9995, val_loss: 3.9990, lr: 0.000010, 0.08s
2023-04-10 20:35:01,580 - INFO - Saved model at 61
2023-04-10 20:35:01,580 - INFO - Val loss decrease from 3.9995 to 3.9990, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch61.tar
2023-04-10 20:35:01,625 - INFO - epoch complete!
2023-04-10 20:35:01,626 - INFO - evaluating now!
2023-04-10 20:35:01,651 - INFO - Epoch [62/100] train_loss: 3.9990, val_loss: 3.9986, lr: 0.000010, 0.07s
2023-04-10 20:35:01,660 - INFO - Saved model at 62
2023-04-10 20:35:01,660 - INFO - Val loss decrease from 3.9990 to 3.9986, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch62.tar
2023-04-10 20:35:01,694 - INFO - epoch complete!
2023-04-10 20:35:01,694 - INFO - evaluating now!
2023-04-10 20:35:01,711 - INFO - Epoch [63/100] train_loss: 3.9986, val_loss: 3.9982, lr: 0.000010, 0.05s
2023-04-10 20:35:01,719 - INFO - Saved model at 63
2023-04-10 20:35:01,719 - INFO - Val loss decrease from 3.9986 to 3.9982, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch63.tar
2023-04-10 20:35:01,762 - INFO - epoch complete!
2023-04-10 20:35:01,762 - INFO - evaluating now!
2023-04-10 20:35:01,786 - INFO - Epoch [64/100] train_loss: 3.9982, val_loss: 3.9978, lr: 0.000010, 0.07s
2023-04-10 20:35:01,796 - INFO - Saved model at 64
2023-04-10 20:35:01,797 - INFO - Val loss decrease from 3.9982 to 3.9978, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch64.tar
2023-04-10 20:35:01,836 - INFO - epoch complete!
2023-04-10 20:35:01,836 - INFO - evaluating now!
2023-04-10 20:35:01,861 - INFO - Epoch [65/100] train_loss: 3.9978, val_loss: 3.9974, lr: 0.000010, 0.06s
2023-04-10 20:35:01,868 - INFO - Saved model at 65
2023-04-10 20:35:01,869 - INFO - Val loss decrease from 3.9978 to 3.9974, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch65.tar
2023-04-10 20:35:01,905 - INFO - epoch complete!
2023-04-10 20:35:01,905 - INFO - evaluating now!
2023-04-10 20:35:01,922 - INFO - Epoch [66/100] train_loss: 3.9974, val_loss: 3.9969, lr: 0.000010, 0.05s
2023-04-10 20:35:01,930 - INFO - Saved model at 66
2023-04-10 20:35:01,931 - INFO - Val loss decrease from 3.9974 to 3.9969, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch66.tar
2023-04-10 20:35:01,966 - INFO - epoch complete!
2023-04-10 20:35:01,966 - INFO - evaluating now!
2023-04-10 20:35:01,988 - INFO - Epoch [67/100] train_loss: 3.9969, val_loss: 3.9965, lr: 0.000010, 0.06s
2023-04-10 20:35:01,997 - INFO - Saved model at 67
2023-04-10 20:35:01,997 - INFO - Val loss decrease from 3.9969 to 3.9965, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch67.tar
2023-04-10 20:35:02,036 - INFO - epoch complete!
2023-04-10 20:35:02,037 - INFO - evaluating now!
2023-04-10 20:35:02,060 - INFO - Epoch [68/100] train_loss: 3.9965, val_loss: 3.9961, lr: 0.000010, 0.06s
2023-04-10 20:35:02,069 - INFO - Saved model at 68
2023-04-10 20:35:02,069 - INFO - Val loss decrease from 3.9965 to 3.9961, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch68.tar
2023-04-10 20:35:02,110 - INFO - epoch complete!
2023-04-10 20:35:02,110 - INFO - evaluating now!
2023-04-10 20:35:02,134 - INFO - Epoch [69/100] train_loss: 3.9961, val_loss: 3.9957, lr: 0.000001, 0.07s
2023-04-10 20:35:02,143 - INFO - Saved model at 69
2023-04-10 20:35:02,143 - INFO - Val loss decrease from 3.9961 to 3.9957, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch69.tar
2023-04-10 20:35:02,194 - INFO - epoch complete!
2023-04-10 20:35:02,194 - INFO - evaluating now!
2023-04-10 20:35:02,216 - INFO - Epoch [70/100] train_loss: 3.9957, val_loss: 3.9956, lr: 0.000001, 0.07s
2023-04-10 20:35:02,225 - INFO - Saved model at 70
2023-04-10 20:35:02,225 - INFO - Val loss decrease from 3.9957 to 3.9956, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch70.tar
2023-04-10 20:35:02,278 - INFO - epoch complete!
2023-04-10 20:35:02,278 - INFO - evaluating now!
2023-04-10 20:35:02,297 - INFO - Epoch [71/100] train_loss: 3.9956, val_loss: 3.9956, lr: 0.000001, 0.07s
2023-04-10 20:35:02,305 - INFO - Saved model at 71
2023-04-10 20:35:02,305 - INFO - Val loss decrease from 3.9956 to 3.9956, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch71.tar
2023-04-10 20:35:02,339 - INFO - epoch complete!
2023-04-10 20:35:02,340 - INFO - evaluating now!
2023-04-10 20:35:02,366 - INFO - Epoch [72/100] train_loss: 3.9956, val_loss: 3.9955, lr: 0.000001, 0.06s
2023-04-10 20:35:02,374 - INFO - Saved model at 72
2023-04-10 20:35:02,375 - INFO - Val loss decrease from 3.9956 to 3.9955, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch72.tar
2023-04-10 20:35:02,409 - INFO - epoch complete!
2023-04-10 20:35:02,411 - INFO - evaluating now!
2023-04-10 20:35:02,430 - INFO - Epoch [73/100] train_loss: 3.9955, val_loss: 3.9955, lr: 0.000001, 0.06s
2023-04-10 20:35:02,438 - INFO - Saved model at 73
2023-04-10 20:35:02,439 - INFO - Val loss decrease from 3.9955 to 3.9955, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch73.tar
2023-04-10 20:35:02,471 - INFO - epoch complete!
2023-04-10 20:35:02,472 - INFO - evaluating now!
2023-04-10 20:35:02,492 - INFO - Epoch [74/100] train_loss: 3.9955, val_loss: 3.9954, lr: 0.000001, 0.05s
2023-04-10 20:35:02,502 - INFO - Saved model at 74
2023-04-10 20:35:02,502 - INFO - Val loss decrease from 3.9955 to 3.9954, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch74.tar
2023-04-10 20:35:02,545 - INFO - epoch complete!
2023-04-10 20:35:02,546 - INFO - evaluating now!
2023-04-10 20:35:02,583 - INFO - Epoch [75/100] train_loss: 3.9954, val_loss: 3.9954, lr: 0.000001, 0.08s
2023-04-10 20:35:02,592 - INFO - Saved model at 75
2023-04-10 20:35:02,593 - INFO - Val loss decrease from 3.9954 to 3.9954, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch75.tar
2023-04-10 20:35:02,642 - INFO - epoch complete!
2023-04-10 20:35:02,643 - INFO - evaluating now!
2023-04-10 20:35:02,671 - INFO - Epoch [76/100] train_loss: 3.9954, val_loss: 3.9954, lr: 0.000001, 0.08s
2023-04-10 20:35:02,696 - INFO - Saved model at 76
2023-04-10 20:35:02,697 - INFO - Val loss decrease from 3.9954 to 3.9954, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch76.tar
2023-04-10 20:35:02,757 - INFO - epoch complete!
2023-04-10 20:35:02,757 - INFO - evaluating now!
2023-04-10 20:35:02,786 - INFO - Epoch [77/100] train_loss: 3.9954, val_loss: 3.9953, lr: 0.000001, 0.09s
2023-04-10 20:35:02,797 - INFO - Saved model at 77
2023-04-10 20:35:02,797 - INFO - Val loss decrease from 3.9954 to 3.9953, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch77.tar
2023-04-10 20:35:02,847 - INFO - epoch complete!
2023-04-10 20:35:02,847 - INFO - evaluating now!
2023-04-10 20:35:02,876 - INFO - Epoch [78/100] train_loss: 3.9953, val_loss: 3.9953, lr: 0.000001, 0.08s
2023-04-10 20:35:02,884 - INFO - Saved model at 78
2023-04-10 20:35:02,885 - INFO - Val loss decrease from 3.9953 to 3.9953, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch78.tar
2023-04-10 20:35:02,943 - INFO - epoch complete!
2023-04-10 20:35:02,943 - INFO - evaluating now!
2023-04-10 20:35:02,968 - INFO - Epoch [79/100] train_loss: 3.9953, val_loss: 3.9952, lr: 0.000001, 0.08s
2023-04-10 20:35:02,975 - INFO - Saved model at 79
2023-04-10 20:35:02,975 - INFO - Val loss decrease from 3.9953 to 3.9952, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch79.tar
2023-04-10 20:35:03,044 - INFO - epoch complete!
2023-04-10 20:35:03,044 - INFO - evaluating now!
2023-04-10 20:35:03,078 - INFO - Epoch [80/100] train_loss: 3.9952, val_loss: 3.9952, lr: 0.000001, 0.10s
2023-04-10 20:35:03,087 - INFO - Saved model at 80
2023-04-10 20:35:03,087 - INFO - Val loss decrease from 3.9952 to 3.9952, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch80.tar
2023-04-10 20:35:03,140 - INFO - epoch complete!
2023-04-10 20:35:03,140 - INFO - evaluating now!
2023-04-10 20:35:03,173 - INFO - Epoch [81/100] train_loss: 3.9952, val_loss: 3.9951, lr: 0.000001, 0.09s
2023-04-10 20:35:03,185 - INFO - Saved model at 81
2023-04-10 20:35:03,185 - INFO - Val loss decrease from 3.9952 to 3.9951, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch81.tar
2023-04-10 20:35:03,230 - INFO - epoch complete!
2023-04-10 20:35:03,230 - INFO - evaluating now!
2023-04-10 20:35:03,251 - INFO - Epoch [82/100] train_loss: 3.9951, val_loss: 3.9951, lr: 0.000001, 0.07s
2023-04-10 20:35:03,261 - INFO - Saved model at 82
2023-04-10 20:35:03,261 - INFO - Val loss decrease from 3.9951 to 3.9951, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch82.tar
2023-04-10 20:35:03,316 - INFO - epoch complete!
2023-04-10 20:35:03,317 - INFO - evaluating now!
2023-04-10 20:35:03,350 - INFO - Epoch [83/100] train_loss: 3.9951, val_loss: 3.9950, lr: 0.000001, 0.09s
2023-04-10 20:35:03,358 - INFO - Saved model at 83
2023-04-10 20:35:03,358 - INFO - Val loss decrease from 3.9951 to 3.9950, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch83.tar
2023-04-10 20:35:03,405 - INFO - epoch complete!
2023-04-10 20:35:03,406 - INFO - evaluating now!
2023-04-10 20:35:03,429 - INFO - Epoch [84/100] train_loss: 3.9950, val_loss: 3.9950, lr: 0.000001, 0.07s
2023-04-10 20:35:03,437 - INFO - Saved model at 84
2023-04-10 20:35:03,437 - INFO - Val loss decrease from 3.9950 to 3.9950, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch84.tar
2023-04-10 20:35:03,480 - INFO - epoch complete!
2023-04-10 20:35:03,481 - INFO - evaluating now!
2023-04-10 20:35:03,501 - INFO - Epoch [85/100] train_loss: 3.9950, val_loss: 3.9950, lr: 0.000001, 0.06s
2023-04-10 20:35:03,516 - INFO - Saved model at 85
2023-04-10 20:35:03,517 - INFO - Val loss decrease from 3.9950 to 3.9950, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch85.tar
2023-04-10 20:35:03,564 - INFO - epoch complete!
2023-04-10 20:35:03,564 - INFO - evaluating now!
2023-04-10 20:35:03,593 - INFO - Epoch [86/100] train_loss: 3.9950, val_loss: 3.9949, lr: 0.000001, 0.08s
2023-04-10 20:35:03,600 - INFO - Saved model at 86
2023-04-10 20:35:03,600 - INFO - Val loss decrease from 3.9950 to 3.9949, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch86.tar
2023-04-10 20:35:03,650 - INFO - epoch complete!
2023-04-10 20:35:03,650 - INFO - evaluating now!
2023-04-10 20:35:03,670 - INFO - Epoch [87/100] train_loss: 3.9949, val_loss: 3.9949, lr: 0.000001, 0.07s
2023-04-10 20:35:03,677 - INFO - Saved model at 87
2023-04-10 20:35:03,677 - INFO - Val loss decrease from 3.9949 to 3.9949, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch87.tar
2023-04-10 20:35:03,736 - INFO - epoch complete!
2023-04-10 20:35:03,736 - INFO - evaluating now!
2023-04-10 20:35:03,758 - INFO - Epoch [88/100] train_loss: 3.9949, val_loss: 3.9948, lr: 0.000001, 0.08s
2023-04-10 20:35:03,766 - INFO - Saved model at 88
2023-04-10 20:35:03,766 - INFO - Val loss decrease from 3.9949 to 3.9948, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch88.tar
2023-04-10 20:35:03,808 - INFO - epoch complete!
2023-04-10 20:35:03,808 - INFO - evaluating now!
2023-04-10 20:35:03,828 - INFO - Epoch [89/100] train_loss: 3.9948, val_loss: 3.9948, lr: 0.000001, 0.06s
2023-04-10 20:35:03,845 - INFO - Saved model at 89
2023-04-10 20:35:03,845 - INFO - Val loss decrease from 3.9948 to 3.9948, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch89.tar
2023-04-10 20:35:03,882 - INFO - epoch complete!
2023-04-10 20:35:03,883 - INFO - evaluating now!
2023-04-10 20:35:03,903 - INFO - Epoch [90/100] train_loss: 3.9948, val_loss: 3.9947, lr: 0.000001, 0.06s
2023-04-10 20:35:03,910 - INFO - Saved model at 90
2023-04-10 20:35:03,910 - INFO - Val loss decrease from 3.9948 to 3.9947, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch90.tar
2023-04-10 20:35:03,948 - INFO - epoch complete!
2023-04-10 20:35:03,948 - INFO - evaluating now!
2023-04-10 20:35:03,990 - INFO - Epoch [91/100] train_loss: 3.9947, val_loss: 3.9947, lr: 0.000001, 0.08s
2023-04-10 20:35:04,010 - INFO - Saved model at 91
2023-04-10 20:35:04,010 - INFO - Val loss decrease from 3.9947 to 3.9947, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch91.tar
2023-04-10 20:35:04,052 - INFO - epoch complete!
2023-04-10 20:35:04,053 - INFO - evaluating now!
2023-04-10 20:35:04,083 - INFO - Epoch [92/100] train_loss: 3.9947, val_loss: 3.9946, lr: 0.000001, 0.07s
2023-04-10 20:35:04,103 - INFO - Saved model at 92
2023-04-10 20:35:04,103 - INFO - Val loss decrease from 3.9947 to 3.9946, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch92.tar
2023-04-10 20:35:04,155 - INFO - epoch complete!
2023-04-10 20:35:04,156 - INFO - evaluating now!
2023-04-10 20:35:04,183 - INFO - Epoch [93/100] train_loss: 3.9946, val_loss: 3.9946, lr: 0.000001, 0.08s
2023-04-10 20:35:04,192 - INFO - Saved model at 93
2023-04-10 20:35:04,193 - INFO - Val loss decrease from 3.9946 to 3.9946, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch93.tar
2023-04-10 20:35:04,238 - INFO - epoch complete!
2023-04-10 20:35:04,239 - INFO - evaluating now!
2023-04-10 20:35:04,262 - INFO - Epoch [94/100] train_loss: 3.9946, val_loss: 3.9946, lr: 0.000001, 0.07s
2023-04-10 20:35:04,272 - INFO - Saved model at 94
2023-04-10 20:35:04,272 - INFO - Val loss decrease from 3.9946 to 3.9946, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch94.tar
2023-04-10 20:35:04,310 - INFO - epoch complete!
2023-04-10 20:35:04,310 - INFO - evaluating now!
2023-04-10 20:35:04,334 - INFO - Epoch [95/100] train_loss: 3.9946, val_loss: 3.9945, lr: 0.000001, 0.06s
2023-04-10 20:35:04,343 - INFO - Saved model at 95
2023-04-10 20:35:04,343 - INFO - Val loss decrease from 3.9946 to 3.9945, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch95.tar
2023-04-10 20:35:04,387 - INFO - epoch complete!
2023-04-10 20:35:04,388 - INFO - evaluating now!
2023-04-10 20:35:04,410 - INFO - Epoch [96/100] train_loss: 3.9945, val_loss: 3.9945, lr: 0.000001, 0.07s
2023-04-10 20:35:04,421 - INFO - Saved model at 96
2023-04-10 20:35:04,421 - INFO - Val loss decrease from 3.9945 to 3.9945, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch96.tar
2023-04-10 20:35:04,487 - INFO - epoch complete!
2023-04-10 20:35:04,488 - INFO - evaluating now!
2023-04-10 20:35:04,512 - INFO - Epoch [97/100] train_loss: 3.9945, val_loss: 3.9944, lr: 0.000001, 0.09s
2023-04-10 20:35:04,520 - INFO - Saved model at 97
2023-04-10 20:35:04,520 - INFO - Val loss decrease from 3.9945 to 3.9944, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch97.tar
2023-04-10 20:35:04,562 - INFO - epoch complete!
2023-04-10 20:35:04,563 - INFO - evaluating now!
2023-04-10 20:35:04,590 - INFO - Epoch [98/100] train_loss: 3.9944, val_loss: 3.9944, lr: 0.000001, 0.07s
2023-04-10 20:35:04,600 - INFO - Saved model at 98
2023-04-10 20:35:04,600 - INFO - Val loss decrease from 3.9944 to 3.9944, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch98.tar
2023-04-10 20:35:04,653 - INFO - epoch complete!
2023-04-10 20:35:04,653 - INFO - evaluating now!
2023-04-10 20:35:04,676 - INFO - Epoch [99/100] train_loss: 3.9944, val_loss: 3.9943, lr: 0.000001, 0.08s
2023-04-10 20:35:04,684 - INFO - Saved model at 99
2023-04-10 20:35:04,684 - INFO - Val loss decrease from 3.9944 to 3.9943, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch99.tar
2023-04-10 20:35:04,684 - INFO - Trained totally 100 epochs, average train time is 0.044s, average eval time is 0.024s
2023-04-10 20:35:04,705 - INFO - Loaded model at 99
2023-04-10 20:35:04,706 - INFO - Saved model at ./libcity/cache/50001/model_cache/GRU_Xiongan.m
2023-04-10 20:35:04,713 - INFO - Start evaluating ...
2023-04-10 20:35:04,919 - INFO - Note that you select the single mode to evaluate!
2023-04-10 20:35:04,929 - INFO - Evaluate result is saved at ./libcity/cache/50001/evaluate_cache/2023_04_10_20_35_04_RNN_Xiongan.csv
2023-04-10 20:35:04,947 - INFO - 
         MAE      MAPE        MSE      RMSE  masked_MAE  masked_MAPE  masked_MSE  masked_RMSE        R2      EVAR
1   2.229734  0.037293  12.286632  3.505229    2.229734     0.037293   12.286632     3.505229  0.595792  0.597202
2   3.328128  0.055695  20.387779  4.515283    3.328128     0.055695   20.387779     4.515283  0.376135  0.377742
3   4.012466  0.069000  27.123829  5.208054    4.012466     0.069000   27.123829     5.208054  0.203431  0.211363
4   4.116626  0.069293  26.675188  5.164803    4.116626     0.069293   26.675188     5.164803  0.198593  0.198622
5   4.293790  0.071557  28.251593  5.315223    4.293790     0.071557   28.251593     5.315223  0.111748  0.117011
6   4.129027  0.069602  27.347088  5.229445    4.129027     0.069602   27.347088     5.229445  0.175803  0.176098
7   4.291425  0.073063  28.898994  5.375779    4.291425     0.073063   28.898994     5.375779  0.091291  0.092700
8   4.445675  0.075392  30.206394  5.496035    4.445675     0.075392   30.206394     5.496035  0.113833  0.114262
9   4.330255  0.073308  29.234856  5.406927    4.330255     0.073308   29.234856     5.406927  0.129070  0.129071
10  4.432353  0.074065  31.567749  5.618518    4.432353     0.074065   31.567749     5.618518  0.076330  0.078199
11  4.452794  0.075805  32.272278  5.680870    4.452794     0.075805   32.272278     5.680870  0.036633  0.037942
12  3.869823  0.065332  24.397837  4.939416    3.869823     0.065332   24.397837     4.939416  0.250789  0.251447
