2023-04-10 15:49:52,972 - INFO - Log directory: ./libcity/log
2023-04-10 15:49:52,973 - INFO - Begin pipeline, task=traffic_state_pred, model_name=GRU, dataset_name=Xiongan, exp_id=50001
2023-04-10 15:49:52,973 - INFO - {'task': 'traffic_state_pred', 'model': 'RNN', 'dataset': 'Xiongan', 'saved_model': True, 'train': True, 'exp_id': '50001', 'seed': 0, 'dataset_class': 'TrafficStatePointDataset', 'executor': 'TrafficStateExecutor', 'evaluator': 'TrafficStateEvaluator', 'rnn_type': 'GRU', 'hidden_size': 64, 'num_layers': 1, 'dropout': 0, 'bidirectional': False, 'teacher_forcing_ratio': 0, 'scaler': 'standard', 'load_external': True, 'normal_external': False, 'ext_scaler': 'none', 'add_time_in_day': True, 'add_day_in_week': False, 'max_epoch': 100, 'learner': 'adam', 'learning_rate': 0.01, 'lr_decay': True, 'lr_scheduler': 'multisteplr', 'lr_decay_ratio': 0.1, 'steps': [5, 20, 40, 70], 'clip_grad_norm': True, 'max_grad_norm': 5, 'use_early_stop': True, 'patience': 50, 'batch_size': 64, 'cache_dataset': True, 'num_workers': 0, 'pad_with_last_sample': True, 'train_rate': 0.7, 'eval_rate': 0.1, 'input_window': 12, 'output_window': 12, 'gpu': True, 'gpu_id': 0, 'train_loss': 'none', 'epoch': 0, 'weight_decay': 0, 'lr_epsilon': 1e-08, 'lr_beta1': 0.9, 'lr_beta2': 0.999, 'lr_alpha': 0.99, 'lr_momentum': 0, 'step_size': 10, 'lr_T_max': 30, 'lr_eta_min': 0, 'lr_patience': 10, 'lr_threshold': 0.0001, 'log_level': 'INFO', 'log_every': 1, 'load_best_epoch': True, 'hyper_tune': False, 'metrics': ['MAE', 'MAPE', 'MSE', 'RMSE', 'masked_MAE', 'masked_MAPE', 'masked_MSE', 'masked_RMSE', 'R2', 'EVAR'], 'evaluator_mode': 'single', 'save_mode': ['csv'], 'geo': {'including_types': ['Point'], 'Point': {}}, 'rel': {'including_types': ['geo'], 'geo': {'cost': 'num'}}, 'dyna': {'including_types': ['state'], 'state': {'entity_id': 'geo_id', 'traffic_speed': 'num'}}, 'data_col': ['traffic_speed'], 'weight_col': 'cost', 'data_files': ['Xiongan'], 'geo_file': 'Xiongan', 'rel_file': 'Xiongan', 'output_dim': 1, 'time_intervals': 300, 'init_weight_inf_or_zero': 'inf', 'set_weight_link_or_dist': 'dist', 'calculate_weight_adj': True, 'weight_adj_epsilon': 0.1, 'device': device(type='cuda', index=0)}
2023-04-10 15:49:52,984 - INFO - Loaded file Xiongan.geo, num_nodes=487
2023-04-10 15:49:52,987 - INFO - set_weight_link_or_dist: dist
2023-04-10 15:49:52,987 - INFO - init_weight_inf_or_zero: inf
2023-04-10 15:49:52,991 - INFO - Loaded file Xiongan.rel, shape=(487, 487)
2023-04-10 15:49:52,991 - INFO - Start Calculate the weight by Gauss kernel!
2023-04-10 15:49:52,995 - INFO - Loading ./libcity/cache/dataset_cache/point_based_Xiongan_12_12_0.7_0.1_standard_64_True_True_False_True.npz
2023-04-10 15:49:53,040 - INFO - train	x: (26, 12, 487, 2), y: (26, 12, 487, 2)
2023-04-10 15:49:53,040 - INFO - eval	x: (4, 12, 487, 2), y: (4, 12, 487, 2)
2023-04-10 15:49:53,040 - INFO - test	x: (7, 12, 487, 2), y: (7, 12, 487, 2)
2023-04-10 15:49:53,041 - INFO - StandardScaler mean: 59.92392878005366, std: 5.807862904711059
2023-04-10 15:49:53,041 - INFO - NoneScaler
2023-04-10 15:49:53,293 - INFO - You select rnn_type GRU in RNN!
2023-04-10 15:49:58,206 - INFO - RNN(
  (rnn): GRU(974, 64)
  (fc): Linear(in_features=64, out_features=487, bias=True)
)
2023-04-10 15:49:58,206 - INFO - rnn.weight_ih_l0	torch.Size([192, 974])	cuda:0	True
2023-04-10 15:49:58,206 - INFO - rnn.weight_hh_l0	torch.Size([192, 64])	cuda:0	True
2023-04-10 15:49:58,206 - INFO - rnn.bias_ih_l0	torch.Size([192])	cuda:0	True
2023-04-10 15:49:58,206 - INFO - rnn.bias_hh_l0	torch.Size([192])	cuda:0	True
2023-04-10 15:49:58,207 - INFO - fc.weight	torch.Size([487, 64])	cuda:0	True
2023-04-10 15:49:58,207 - INFO - fc.bias	torch.Size([487])	cuda:0	True
2023-04-10 15:49:58,207 - INFO - Total parameter numbers: 231335
2023-04-10 15:49:58,207 - INFO - You select `adam` optimizer.
2023-04-10 15:49:58,207 - INFO - You select `multisteplr` lr_scheduler.
2023-04-10 15:49:58,208 - WARNING - Received none train loss func and will use the loss func defined in the model.
2023-04-10 15:49:58,208 - INFO - Start training ...
2023-04-10 15:49:58,208 - INFO - num_batches:1
2023-04-10 15:49:58,309 - INFO - epoch complete!
2023-04-10 15:49:58,309 - INFO - evaluating now!
2023-04-10 15:49:58,332 - INFO - Epoch [0/100] train_loss: 5.0072, val_loss: 5.0799, lr: 0.010000, 0.12s
2023-04-10 15:49:58,342 - INFO - Saved model at 0
2023-04-10 15:49:58,342 - INFO - Val loss decrease from inf to 5.0799, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch0.tar
2023-04-10 15:49:58,382 - INFO - epoch complete!
2023-04-10 15:49:58,383 - INFO - evaluating now!
2023-04-10 15:49:58,407 - INFO - Epoch [1/100] train_loss: 5.0799, val_loss: 5.0446, lr: 0.010000, 0.06s
2023-04-10 15:49:58,415 - INFO - Saved model at 1
2023-04-10 15:49:58,415 - INFO - Val loss decrease from 5.0799 to 5.0446, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch1.tar
2023-04-10 15:49:58,454 - INFO - epoch complete!
2023-04-10 15:49:58,454 - INFO - evaluating now!
2023-04-10 15:49:58,477 - INFO - Epoch [2/100] train_loss: 5.0446, val_loss: 4.8182, lr: 0.010000, 0.06s
2023-04-10 15:49:58,485 - INFO - Saved model at 2
2023-04-10 15:49:58,485 - INFO - Val loss decrease from 5.0446 to 4.8182, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch2.tar
2023-04-10 15:49:58,525 - INFO - epoch complete!
2023-04-10 15:49:58,525 - INFO - evaluating now!
2023-04-10 15:49:58,551 - INFO - Epoch [3/100] train_loss: 4.8182, val_loss: 4.6643, lr: 0.010000, 0.07s
2023-04-10 15:49:58,559 - INFO - Saved model at 3
2023-04-10 15:49:58,559 - INFO - Val loss decrease from 4.8182 to 4.6643, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch3.tar
2023-04-10 15:49:58,598 - INFO - epoch complete!
2023-04-10 15:49:58,598 - INFO - evaluating now!
2023-04-10 15:49:58,619 - INFO - Epoch [4/100] train_loss: 4.6643, val_loss: 4.5552, lr: 0.001000, 0.06s
2023-04-10 15:49:58,627 - INFO - Saved model at 4
2023-04-10 15:49:58,627 - INFO - Val loss decrease from 4.6643 to 4.5552, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch4.tar
2023-04-10 15:49:58,665 - INFO - epoch complete!
2023-04-10 15:49:58,665 - INFO - evaluating now!
2023-04-10 15:49:58,687 - INFO - Epoch [5/100] train_loss: 4.5552, val_loss: 4.5161, lr: 0.001000, 0.06s
2023-04-10 15:49:58,694 - INFO - Saved model at 5
2023-04-10 15:49:58,695 - INFO - Val loss decrease from 4.5552 to 4.5161, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch5.tar
2023-04-10 15:49:58,735 - INFO - epoch complete!
2023-04-10 15:49:58,735 - INFO - evaluating now!
2023-04-10 15:49:58,757 - INFO - Epoch [6/100] train_loss: 4.5161, val_loss: 4.4734, lr: 0.001000, 0.06s
2023-04-10 15:49:58,765 - INFO - Saved model at 6
2023-04-10 15:49:58,765 - INFO - Val loss decrease from 4.5161 to 4.4734, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch6.tar
2023-04-10 15:49:58,801 - INFO - epoch complete!
2023-04-10 15:49:58,801 - INFO - evaluating now!
2023-04-10 15:49:58,822 - INFO - Epoch [7/100] train_loss: 4.4734, val_loss: 4.4345, lr: 0.001000, 0.06s
2023-04-10 15:49:58,830 - INFO - Saved model at 7
2023-04-10 15:49:58,830 - INFO - Val loss decrease from 4.4734 to 4.4345, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch7.tar
2023-04-10 15:49:58,875 - INFO - epoch complete!
2023-04-10 15:49:58,875 - INFO - evaluating now!
2023-04-10 15:49:58,898 - INFO - Epoch [8/100] train_loss: 4.4345, val_loss: 4.3996, lr: 0.001000, 0.07s
2023-04-10 15:49:58,906 - INFO - Saved model at 8
2023-04-10 15:49:58,906 - INFO - Val loss decrease from 4.4345 to 4.3996, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch8.tar
2023-04-10 15:49:58,946 - INFO - epoch complete!
2023-04-10 15:49:58,946 - INFO - evaluating now!
2023-04-10 15:49:58,969 - INFO - Epoch [9/100] train_loss: 4.3996, val_loss: 4.3682, lr: 0.001000, 0.06s
2023-04-10 15:49:58,976 - INFO - Saved model at 9
2023-04-10 15:49:58,977 - INFO - Val loss decrease from 4.3996 to 4.3682, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch9.tar
2023-04-10 15:49:59,014 - INFO - epoch complete!
2023-04-10 15:49:59,015 - INFO - evaluating now!
2023-04-10 15:49:59,036 - INFO - Epoch [10/100] train_loss: 4.3682, val_loss: 4.3399, lr: 0.001000, 0.06s
2023-04-10 15:49:59,043 - INFO - Saved model at 10
2023-04-10 15:49:59,044 - INFO - Val loss decrease from 4.3682 to 4.3399, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch10.tar
2023-04-10 15:49:59,081 - INFO - epoch complete!
2023-04-10 15:49:59,082 - INFO - evaluating now!
2023-04-10 15:49:59,104 - INFO - Epoch [11/100] train_loss: 4.3399, val_loss: 4.3108, lr: 0.001000, 0.06s
2023-04-10 15:49:59,111 - INFO - Saved model at 11
2023-04-10 15:49:59,111 - INFO - Val loss decrease from 4.3399 to 4.3108, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch11.tar
2023-04-10 15:49:59,155 - INFO - epoch complete!
2023-04-10 15:49:59,156 - INFO - evaluating now!
2023-04-10 15:49:59,177 - INFO - Epoch [12/100] train_loss: 4.3108, val_loss: 4.2810, lr: 0.001000, 0.07s
2023-04-10 15:49:59,184 - INFO - Saved model at 12
2023-04-10 15:49:59,185 - INFO - Val loss decrease from 4.3108 to 4.2810, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch12.tar
2023-04-10 15:49:59,229 - INFO - epoch complete!
2023-04-10 15:49:59,229 - INFO - evaluating now!
2023-04-10 15:49:59,250 - INFO - Epoch [13/100] train_loss: 4.2810, val_loss: 4.2534, lr: 0.001000, 0.07s
2023-04-10 15:49:59,258 - INFO - Saved model at 13
2023-04-10 15:49:59,258 - INFO - Val loss decrease from 4.2810 to 4.2534, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch13.tar
2023-04-10 15:49:59,302 - INFO - epoch complete!
2023-04-10 15:49:59,303 - INFO - evaluating now!
2023-04-10 15:49:59,324 - INFO - Epoch [14/100] train_loss: 4.2534, val_loss: 4.2256, lr: 0.001000, 0.07s
2023-04-10 15:49:59,332 - INFO - Saved model at 14
2023-04-10 15:49:59,332 - INFO - Val loss decrease from 4.2534 to 4.2256, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch14.tar
2023-04-10 15:49:59,371 - INFO - epoch complete!
2023-04-10 15:49:59,371 - INFO - evaluating now!
2023-04-10 15:49:59,393 - INFO - Epoch [15/100] train_loss: 4.2256, val_loss: 4.1971, lr: 0.001000, 0.06s
2023-04-10 15:49:59,401 - INFO - Saved model at 15
2023-04-10 15:49:59,401 - INFO - Val loss decrease from 4.2256 to 4.1971, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch15.tar
2023-04-10 15:49:59,437 - INFO - epoch complete!
2023-04-10 15:49:59,437 - INFO - evaluating now!
2023-04-10 15:49:59,463 - INFO - Epoch [16/100] train_loss: 4.1971, val_loss: 4.1691, lr: 0.001000, 0.06s
2023-04-10 15:49:59,471 - INFO - Saved model at 16
2023-04-10 15:49:59,471 - INFO - Val loss decrease from 4.1971 to 4.1691, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch16.tar
2023-04-10 15:49:59,509 - INFO - epoch complete!
2023-04-10 15:49:59,509 - INFO - evaluating now!
2023-04-10 15:49:59,531 - INFO - Epoch [17/100] train_loss: 4.1691, val_loss: 4.1415, lr: 0.001000, 0.06s
2023-04-10 15:49:59,538 - INFO - Saved model at 17
2023-04-10 15:49:59,538 - INFO - Val loss decrease from 4.1691 to 4.1415, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch17.tar
2023-04-10 15:49:59,579 - INFO - epoch complete!
2023-04-10 15:49:59,579 - INFO - evaluating now!
2023-04-10 15:49:59,601 - INFO - Epoch [18/100] train_loss: 4.1415, val_loss: 4.1132, lr: 0.001000, 0.06s
2023-04-10 15:49:59,610 - INFO - Saved model at 18
2023-04-10 15:49:59,610 - INFO - Val loss decrease from 4.1415 to 4.1132, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch18.tar
2023-04-10 15:49:59,645 - INFO - epoch complete!
2023-04-10 15:49:59,645 - INFO - evaluating now!
2023-04-10 15:49:59,670 - INFO - Epoch [19/100] train_loss: 4.1132, val_loss: 4.0852, lr: 0.000100, 0.06s
2023-04-10 15:49:59,678 - INFO - Saved model at 19
2023-04-10 15:49:59,678 - INFO - Val loss decrease from 4.1132 to 4.0852, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch19.tar
2023-04-10 15:49:59,717 - INFO - epoch complete!
2023-04-10 15:49:59,717 - INFO - evaluating now!
2023-04-10 15:49:59,738 - INFO - Epoch [20/100] train_loss: 4.0852, val_loss: 4.0822, lr: 0.000100, 0.06s
2023-04-10 15:49:59,745 - INFO - Saved model at 20
2023-04-10 15:49:59,745 - INFO - Val loss decrease from 4.0852 to 4.0822, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch20.tar
2023-04-10 15:49:59,789 - INFO - epoch complete!
2023-04-10 15:49:59,790 - INFO - evaluating now!
2023-04-10 15:49:59,810 - INFO - Epoch [21/100] train_loss: 4.0822, val_loss: 4.0788, lr: 0.000100, 0.06s
2023-04-10 15:49:59,818 - INFO - Saved model at 21
2023-04-10 15:49:59,818 - INFO - Val loss decrease from 4.0822 to 4.0788, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch21.tar
2023-04-10 15:49:59,860 - INFO - epoch complete!
2023-04-10 15:49:59,861 - INFO - evaluating now!
2023-04-10 15:49:59,884 - INFO - Epoch [22/100] train_loss: 4.0788, val_loss: 4.0752, lr: 0.000100, 0.07s
2023-04-10 15:49:59,892 - INFO - Saved model at 22
2023-04-10 15:49:59,892 - INFO - Val loss decrease from 4.0788 to 4.0752, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch22.tar
2023-04-10 15:49:59,929 - INFO - epoch complete!
2023-04-10 15:49:59,929 - INFO - evaluating now!
2023-04-10 15:49:59,949 - INFO - Epoch [23/100] train_loss: 4.0752, val_loss: 4.0714, lr: 0.000100, 0.06s
2023-04-10 15:49:59,956 - INFO - Saved model at 23
2023-04-10 15:49:59,956 - INFO - Val loss decrease from 4.0752 to 4.0714, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch23.tar
2023-04-10 15:49:59,993 - INFO - epoch complete!
2023-04-10 15:49:59,993 - INFO - evaluating now!
2023-04-10 15:50:00,017 - INFO - Epoch [24/100] train_loss: 4.0714, val_loss: 4.0675, lr: 0.000100, 0.06s
2023-04-10 15:50:00,025 - INFO - Saved model at 24
2023-04-10 15:50:00,025 - INFO - Val loss decrease from 4.0714 to 4.0675, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch24.tar
2023-04-10 15:50:00,071 - INFO - epoch complete!
2023-04-10 15:50:00,071 - INFO - evaluating now!
2023-04-10 15:50:00,094 - INFO - Epoch [25/100] train_loss: 4.0675, val_loss: 4.0636, lr: 0.000100, 0.07s
2023-04-10 15:50:00,102 - INFO - Saved model at 25
2023-04-10 15:50:00,102 - INFO - Val loss decrease from 4.0675 to 4.0636, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch25.tar
2023-04-10 15:50:00,141 - INFO - epoch complete!
2023-04-10 15:50:00,142 - INFO - evaluating now!
2023-04-10 15:50:00,163 - INFO - Epoch [26/100] train_loss: 4.0636, val_loss: 4.0596, lr: 0.000100, 0.06s
2023-04-10 15:50:00,170 - INFO - Saved model at 26
2023-04-10 15:50:00,170 - INFO - Val loss decrease from 4.0636 to 4.0596, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch26.tar
2023-04-10 15:50:00,206 - INFO - epoch complete!
2023-04-10 15:50:00,206 - INFO - evaluating now!
2023-04-10 15:50:00,230 - INFO - Epoch [27/100] train_loss: 4.0596, val_loss: 4.0557, lr: 0.000100, 0.06s
2023-04-10 15:50:00,237 - INFO - Saved model at 27
2023-04-10 15:50:00,237 - INFO - Val loss decrease from 4.0596 to 4.0557, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch27.tar
2023-04-10 15:50:00,277 - INFO - epoch complete!
2023-04-10 15:50:00,277 - INFO - evaluating now!
2023-04-10 15:50:00,302 - INFO - Epoch [28/100] train_loss: 4.0557, val_loss: 4.0517, lr: 0.000100, 0.06s
2023-04-10 15:50:00,316 - INFO - Saved model at 28
2023-04-10 15:50:00,316 - INFO - Val loss decrease from 4.0557 to 4.0517, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch28.tar
2023-04-10 15:50:00,354 - INFO - epoch complete!
2023-04-10 15:50:00,354 - INFO - evaluating now!
2023-04-10 15:50:00,378 - INFO - Epoch [29/100] train_loss: 4.0517, val_loss: 4.0478, lr: 0.000100, 0.06s
2023-04-10 15:50:00,385 - INFO - Saved model at 29
2023-04-10 15:50:00,385 - INFO - Val loss decrease from 4.0517 to 4.0478, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch29.tar
2023-04-10 15:50:00,426 - INFO - epoch complete!
2023-04-10 15:50:00,427 - INFO - evaluating now!
2023-04-10 15:50:00,448 - INFO - Epoch [30/100] train_loss: 4.0478, val_loss: 4.0438, lr: 0.000100, 0.06s
2023-04-10 15:50:00,455 - INFO - Saved model at 30
2023-04-10 15:50:00,456 - INFO - Val loss decrease from 4.0478 to 4.0438, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch30.tar
2023-04-10 15:50:00,497 - INFO - epoch complete!
2023-04-10 15:50:00,498 - INFO - evaluating now!
2023-04-10 15:50:00,519 - INFO - Epoch [31/100] train_loss: 4.0438, val_loss: 4.0399, lr: 0.000100, 0.06s
2023-04-10 15:50:00,526 - INFO - Saved model at 31
2023-04-10 15:50:00,527 - INFO - Val loss decrease from 4.0438 to 4.0399, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch31.tar
2023-04-10 15:50:00,570 - INFO - epoch complete!
2023-04-10 15:50:00,571 - INFO - evaluating now!
2023-04-10 15:50:00,592 - INFO - Epoch [32/100] train_loss: 4.0399, val_loss: 4.0358, lr: 0.000100, 0.07s
2023-04-10 15:50:00,599 - INFO - Saved model at 32
2023-04-10 15:50:00,599 - INFO - Val loss decrease from 4.0399 to 4.0358, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch32.tar
2023-04-10 15:50:00,640 - INFO - epoch complete!
2023-04-10 15:50:00,640 - INFO - evaluating now!
2023-04-10 15:50:00,665 - INFO - Epoch [33/100] train_loss: 4.0358, val_loss: 4.0318, lr: 0.000100, 0.07s
2023-04-10 15:50:00,673 - INFO - Saved model at 33
2023-04-10 15:50:00,673 - INFO - Val loss decrease from 4.0358 to 4.0318, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch33.tar
2023-04-10 15:50:00,712 - INFO - epoch complete!
2023-04-10 15:50:00,712 - INFO - evaluating now!
2023-04-10 15:50:00,734 - INFO - Epoch [34/100] train_loss: 4.0318, val_loss: 4.0279, lr: 0.000100, 0.06s
2023-04-10 15:50:00,742 - INFO - Saved model at 34
2023-04-10 15:50:00,742 - INFO - Val loss decrease from 4.0318 to 4.0279, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch34.tar
2023-04-10 15:50:00,783 - INFO - epoch complete!
2023-04-10 15:50:00,784 - INFO - evaluating now!
2023-04-10 15:50:00,805 - INFO - Epoch [35/100] train_loss: 4.0279, val_loss: 4.0240, lr: 0.000100, 0.06s
2023-04-10 15:50:00,812 - INFO - Saved model at 35
2023-04-10 15:50:00,813 - INFO - Val loss decrease from 4.0279 to 4.0240, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch35.tar
2023-04-10 15:50:00,852 - INFO - epoch complete!
2023-04-10 15:50:00,853 - INFO - evaluating now!
2023-04-10 15:50:00,875 - INFO - Epoch [36/100] train_loss: 4.0240, val_loss: 4.0201, lr: 0.000100, 0.06s
2023-04-10 15:50:00,883 - INFO - Saved model at 36
2023-04-10 15:50:00,883 - INFO - Val loss decrease from 4.0240 to 4.0201, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch36.tar
2023-04-10 15:50:00,916 - INFO - epoch complete!
2023-04-10 15:50:00,916 - INFO - evaluating now!
2023-04-10 15:50:00,938 - INFO - Epoch [37/100] train_loss: 4.0201, val_loss: 4.0162, lr: 0.000100, 0.05s
2023-04-10 15:50:00,945 - INFO - Saved model at 37
2023-04-10 15:50:00,945 - INFO - Val loss decrease from 4.0201 to 4.0162, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch37.tar
2023-04-10 15:50:00,979 - INFO - epoch complete!
2023-04-10 15:50:00,979 - INFO - evaluating now!
2023-04-10 15:50:01,001 - INFO - Epoch [38/100] train_loss: 4.0162, val_loss: 4.0124, lr: 0.000100, 0.06s
2023-04-10 15:50:01,009 - INFO - Saved model at 38
2023-04-10 15:50:01,009 - INFO - Val loss decrease from 4.0162 to 4.0124, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch38.tar
2023-04-10 15:50:01,048 - INFO - epoch complete!
2023-04-10 15:50:01,048 - INFO - evaluating now!
2023-04-10 15:50:01,069 - INFO - Epoch [39/100] train_loss: 4.0124, val_loss: 4.0086, lr: 0.000010, 0.06s
2023-04-10 15:50:01,078 - INFO - Saved model at 39
2023-04-10 15:50:01,078 - INFO - Val loss decrease from 4.0124 to 4.0086, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch39.tar
2023-04-10 15:50:01,113 - INFO - epoch complete!
2023-04-10 15:50:01,114 - INFO - evaluating now!
2023-04-10 15:50:01,135 - INFO - Epoch [40/100] train_loss: 4.0086, val_loss: 4.0082, lr: 0.000010, 0.06s
2023-04-10 15:50:01,142 - INFO - Saved model at 40
2023-04-10 15:50:01,143 - INFO - Val loss decrease from 4.0086 to 4.0082, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch40.tar
2023-04-10 15:50:01,179 - INFO - epoch complete!
2023-04-10 15:50:01,180 - INFO - evaluating now!
2023-04-10 15:50:01,201 - INFO - Epoch [41/100] train_loss: 4.0082, val_loss: 4.0078, lr: 0.000010, 0.06s
2023-04-10 15:50:01,209 - INFO - Saved model at 41
2023-04-10 15:50:01,209 - INFO - Val loss decrease from 4.0082 to 4.0078, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch41.tar
2023-04-10 15:50:01,247 - INFO - epoch complete!
2023-04-10 15:50:01,248 - INFO - evaluating now!
2023-04-10 15:50:01,270 - INFO - Epoch [42/100] train_loss: 4.0078, val_loss: 4.0073, lr: 0.000010, 0.06s
2023-04-10 15:50:01,277 - INFO - Saved model at 42
2023-04-10 15:50:01,278 - INFO - Val loss decrease from 4.0078 to 4.0073, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch42.tar
2023-04-10 15:50:01,312 - INFO - epoch complete!
2023-04-10 15:50:01,312 - INFO - evaluating now!
2023-04-10 15:50:01,334 - INFO - Epoch [43/100] train_loss: 4.0073, val_loss: 4.0069, lr: 0.000010, 0.06s
2023-04-10 15:50:01,341 - INFO - Saved model at 43
2023-04-10 15:50:01,341 - INFO - Val loss decrease from 4.0073 to 4.0069, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch43.tar
2023-04-10 15:50:01,377 - INFO - epoch complete!
2023-04-10 15:50:01,378 - INFO - evaluating now!
2023-04-10 15:50:01,399 - INFO - Epoch [44/100] train_loss: 4.0069, val_loss: 4.0065, lr: 0.000010, 0.06s
2023-04-10 15:50:01,406 - INFO - Saved model at 44
2023-04-10 15:50:01,406 - INFO - Val loss decrease from 4.0069 to 4.0065, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch44.tar
2023-04-10 15:50:01,442 - INFO - epoch complete!
2023-04-10 15:50:01,442 - INFO - evaluating now!
2023-04-10 15:50:01,463 - INFO - Epoch [45/100] train_loss: 4.0065, val_loss: 4.0061, lr: 0.000010, 0.06s
2023-04-10 15:50:01,470 - INFO - Saved model at 45
2023-04-10 15:50:01,471 - INFO - Val loss decrease from 4.0065 to 4.0061, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch45.tar
2023-04-10 15:50:01,507 - INFO - epoch complete!
2023-04-10 15:50:01,507 - INFO - evaluating now!
2023-04-10 15:50:01,531 - INFO - Epoch [46/100] train_loss: 4.0061, val_loss: 4.0057, lr: 0.000010, 0.06s
2023-04-10 15:50:01,538 - INFO - Saved model at 46
2023-04-10 15:50:01,538 - INFO - Val loss decrease from 4.0061 to 4.0057, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch46.tar
2023-04-10 15:50:01,573 - INFO - epoch complete!
2023-04-10 15:50:01,574 - INFO - evaluating now!
2023-04-10 15:50:01,597 - INFO - Epoch [47/100] train_loss: 4.0057, val_loss: 4.0052, lr: 0.000010, 0.06s
2023-04-10 15:50:01,604 - INFO - Saved model at 47
2023-04-10 15:50:01,605 - INFO - Val loss decrease from 4.0057 to 4.0052, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch47.tar
2023-04-10 15:50:01,637 - INFO - epoch complete!
2023-04-10 15:50:01,637 - INFO - evaluating now!
2023-04-10 15:50:01,664 - INFO - Epoch [48/100] train_loss: 4.0052, val_loss: 4.0048, lr: 0.000010, 0.06s
2023-04-10 15:50:01,672 - INFO - Saved model at 48
2023-04-10 15:50:01,672 - INFO - Val loss decrease from 4.0052 to 4.0048, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch48.tar
2023-04-10 15:50:01,705 - INFO - epoch complete!
2023-04-10 15:50:01,706 - INFO - evaluating now!
2023-04-10 15:50:01,733 - INFO - Epoch [49/100] train_loss: 4.0048, val_loss: 4.0044, lr: 0.000010, 0.06s
2023-04-10 15:50:01,740 - INFO - Saved model at 49
2023-04-10 15:50:01,740 - INFO - Val loss decrease from 4.0048 to 4.0044, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch49.tar
2023-04-10 15:50:01,776 - INFO - epoch complete!
2023-04-10 15:50:01,776 - INFO - evaluating now!
2023-04-10 15:50:01,797 - INFO - Epoch [50/100] train_loss: 4.0044, val_loss: 4.0040, lr: 0.000010, 0.06s
2023-04-10 15:50:01,804 - INFO - Saved model at 50
2023-04-10 15:50:01,804 - INFO - Val loss decrease from 4.0044 to 4.0040, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch50.tar
2023-04-10 15:50:01,846 - INFO - epoch complete!
2023-04-10 15:50:01,846 - INFO - evaluating now!
2023-04-10 15:50:01,868 - INFO - Epoch [51/100] train_loss: 4.0040, val_loss: 4.0035, lr: 0.000010, 0.06s
2023-04-10 15:50:01,876 - INFO - Saved model at 51
2023-04-10 15:50:01,876 - INFO - Val loss decrease from 4.0040 to 4.0035, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch51.tar
2023-04-10 15:50:01,921 - INFO - epoch complete!
2023-04-10 15:50:01,921 - INFO - evaluating now!
2023-04-10 15:50:01,948 - INFO - Epoch [52/100] train_loss: 4.0035, val_loss: 4.0031, lr: 0.000010, 0.07s
2023-04-10 15:50:01,956 - INFO - Saved model at 52
2023-04-10 15:50:01,956 - INFO - Val loss decrease from 4.0035 to 4.0031, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch52.tar
2023-04-10 15:50:02,001 - INFO - epoch complete!
2023-04-10 15:50:02,001 - INFO - evaluating now!
2023-04-10 15:50:02,028 - INFO - Epoch [53/100] train_loss: 4.0031, val_loss: 4.0027, lr: 0.000010, 0.07s
2023-04-10 15:50:02,035 - INFO - Saved model at 53
2023-04-10 15:50:02,036 - INFO - Val loss decrease from 4.0031 to 4.0027, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch53.tar
2023-04-10 15:50:02,081 - INFO - epoch complete!
2023-04-10 15:50:02,081 - INFO - evaluating now!
2023-04-10 15:50:02,103 - INFO - Epoch [54/100] train_loss: 4.0027, val_loss: 4.0023, lr: 0.000010, 0.07s
2023-04-10 15:50:02,110 - INFO - Saved model at 54
2023-04-10 15:50:02,110 - INFO - Val loss decrease from 4.0027 to 4.0023, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch54.tar
2023-04-10 15:50:02,153 - INFO - epoch complete!
2023-04-10 15:50:02,153 - INFO - evaluating now!
2023-04-10 15:50:02,177 - INFO - Epoch [55/100] train_loss: 4.0023, val_loss: 4.0018, lr: 0.000010, 0.07s
2023-04-10 15:50:02,185 - INFO - Saved model at 55
2023-04-10 15:50:02,185 - INFO - Val loss decrease from 4.0023 to 4.0018, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch55.tar
2023-04-10 15:50:02,225 - INFO - epoch complete!
2023-04-10 15:50:02,225 - INFO - evaluating now!
2023-04-10 15:50:02,246 - INFO - Epoch [56/100] train_loss: 4.0018, val_loss: 4.0014, lr: 0.000010, 0.06s
2023-04-10 15:50:02,254 - INFO - Saved model at 56
2023-04-10 15:50:02,254 - INFO - Val loss decrease from 4.0018 to 4.0014, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch56.tar
2023-04-10 15:50:02,292 - INFO - epoch complete!
2023-04-10 15:50:02,293 - INFO - evaluating now!
2023-04-10 15:50:02,318 - INFO - Epoch [57/100] train_loss: 4.0014, val_loss: 4.0010, lr: 0.000010, 0.06s
2023-04-10 15:50:02,325 - INFO - Saved model at 57
2023-04-10 15:50:02,325 - INFO - Val loss decrease from 4.0014 to 4.0010, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch57.tar
2023-04-10 15:50:02,370 - INFO - epoch complete!
2023-04-10 15:50:02,370 - INFO - evaluating now!
2023-04-10 15:50:02,390 - INFO - Epoch [58/100] train_loss: 4.0010, val_loss: 4.0005, lr: 0.000010, 0.07s
2023-04-10 15:50:02,398 - INFO - Saved model at 58
2023-04-10 15:50:02,398 - INFO - Val loss decrease from 4.0010 to 4.0005, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch58.tar
2023-04-10 15:50:02,437 - INFO - epoch complete!
2023-04-10 15:50:02,438 - INFO - evaluating now!
2023-04-10 15:50:02,462 - INFO - Epoch [59/100] train_loss: 4.0005, val_loss: 4.0001, lr: 0.000010, 0.06s
2023-04-10 15:50:02,469 - INFO - Saved model at 59
2023-04-10 15:50:02,470 - INFO - Val loss decrease from 4.0005 to 4.0001, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch59.tar
2023-04-10 15:50:02,513 - INFO - epoch complete!
2023-04-10 15:50:02,513 - INFO - evaluating now!
2023-04-10 15:50:02,534 - INFO - Epoch [60/100] train_loss: 4.0001, val_loss: 3.9997, lr: 0.000010, 0.06s
2023-04-10 15:50:02,542 - INFO - Saved model at 60
2023-04-10 15:50:02,542 - INFO - Val loss decrease from 4.0001 to 3.9997, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch60.tar
2023-04-10 15:50:02,588 - INFO - epoch complete!
2023-04-10 15:50:02,589 - INFO - evaluating now!
2023-04-10 15:50:02,610 - INFO - Epoch [61/100] train_loss: 3.9997, val_loss: 3.9993, lr: 0.000010, 0.07s
2023-04-10 15:50:02,618 - INFO - Saved model at 61
2023-04-10 15:50:02,618 - INFO - Val loss decrease from 3.9997 to 3.9993, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch61.tar
2023-04-10 15:50:02,659 - INFO - epoch complete!
2023-04-10 15:50:02,659 - INFO - evaluating now!
2023-04-10 15:50:02,684 - INFO - Epoch [62/100] train_loss: 3.9993, val_loss: 3.9988, lr: 0.000010, 0.07s
2023-04-10 15:50:02,691 - INFO - Saved model at 62
2023-04-10 15:50:02,691 - INFO - Val loss decrease from 3.9993 to 3.9988, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch62.tar
2023-04-10 15:50:02,730 - INFO - epoch complete!
2023-04-10 15:50:02,731 - INFO - evaluating now!
2023-04-10 15:50:02,752 - INFO - Epoch [63/100] train_loss: 3.9988, val_loss: 3.9984, lr: 0.000010, 0.06s
2023-04-10 15:50:02,759 - INFO - Saved model at 63
2023-04-10 15:50:02,760 - INFO - Val loss decrease from 3.9988 to 3.9984, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch63.tar
2023-04-10 15:50:02,806 - INFO - epoch complete!
2023-04-10 15:50:02,807 - INFO - evaluating now!
2023-04-10 15:50:02,829 - INFO - Epoch [64/100] train_loss: 3.9984, val_loss: 3.9980, lr: 0.000010, 0.07s
2023-04-10 15:50:02,836 - INFO - Saved model at 64
2023-04-10 15:50:02,837 - INFO - Val loss decrease from 3.9984 to 3.9980, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch64.tar
2023-04-10 15:50:02,879 - INFO - epoch complete!
2023-04-10 15:50:02,880 - INFO - evaluating now!
2023-04-10 15:50:02,907 - INFO - Epoch [65/100] train_loss: 3.9980, val_loss: 3.9976, lr: 0.000010, 0.07s
2023-04-10 15:50:02,914 - INFO - Saved model at 65
2023-04-10 15:50:02,914 - INFO - Val loss decrease from 3.9980 to 3.9976, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch65.tar
2023-04-10 15:50:02,961 - INFO - epoch complete!
2023-04-10 15:50:02,961 - INFO - evaluating now!
2023-04-10 15:50:02,987 - INFO - Epoch [66/100] train_loss: 3.9976, val_loss: 3.9971, lr: 0.000010, 0.07s
2023-04-10 15:50:02,995 - INFO - Saved model at 66
2023-04-10 15:50:02,995 - INFO - Val loss decrease from 3.9976 to 3.9971, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch66.tar
2023-04-10 15:50:03,044 - INFO - epoch complete!
2023-04-10 15:50:03,045 - INFO - evaluating now!
2023-04-10 15:50:03,067 - INFO - Epoch [67/100] train_loss: 3.9971, val_loss: 3.9967, lr: 0.000010, 0.07s
2023-04-10 15:50:03,075 - INFO - Saved model at 67
2023-04-10 15:50:03,075 - INFO - Val loss decrease from 3.9971 to 3.9967, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch67.tar
2023-04-10 15:50:03,114 - INFO - epoch complete!
2023-04-10 15:50:03,115 - INFO - evaluating now!
2023-04-10 15:50:03,143 - INFO - Epoch [68/100] train_loss: 3.9967, val_loss: 3.9963, lr: 0.000010, 0.07s
2023-04-10 15:50:03,151 - INFO - Saved model at 68
2023-04-10 15:50:03,151 - INFO - Val loss decrease from 3.9967 to 3.9963, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch68.tar
2023-04-10 15:50:03,206 - INFO - epoch complete!
2023-04-10 15:50:03,206 - INFO - evaluating now!
2023-04-10 15:50:03,230 - INFO - Epoch [69/100] train_loss: 3.9963, val_loss: 3.9959, lr: 0.000001, 0.08s
2023-04-10 15:50:03,238 - INFO - Saved model at 69
2023-04-10 15:50:03,238 - INFO - Val loss decrease from 3.9963 to 3.9959, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch69.tar
2023-04-10 15:50:03,278 - INFO - epoch complete!
2023-04-10 15:50:03,279 - INFO - evaluating now!
2023-04-10 15:50:03,300 - INFO - Epoch [70/100] train_loss: 3.9959, val_loss: 3.9958, lr: 0.000001, 0.06s
2023-04-10 15:50:03,308 - INFO - Saved model at 70
2023-04-10 15:50:03,308 - INFO - Val loss decrease from 3.9959 to 3.9958, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch70.tar
2023-04-10 15:50:03,346 - INFO - epoch complete!
2023-04-10 15:50:03,346 - INFO - evaluating now!
2023-04-10 15:50:03,368 - INFO - Epoch [71/100] train_loss: 3.9958, val_loss: 3.9958, lr: 0.000001, 0.06s
2023-04-10 15:50:03,376 - INFO - Saved model at 71
2023-04-10 15:50:03,376 - INFO - Val loss decrease from 3.9958 to 3.9958, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch71.tar
2023-04-10 15:50:03,415 - INFO - epoch complete!
2023-04-10 15:50:03,415 - INFO - evaluating now!
2023-04-10 15:50:03,436 - INFO - Epoch [72/100] train_loss: 3.9958, val_loss: 3.9957, lr: 0.000001, 0.06s
2023-04-10 15:50:03,444 - INFO - Saved model at 72
2023-04-10 15:50:03,444 - INFO - Val loss decrease from 3.9958 to 3.9957, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch72.tar
2023-04-10 15:50:03,481 - INFO - epoch complete!
2023-04-10 15:50:03,481 - INFO - evaluating now!
2023-04-10 15:50:03,503 - INFO - Epoch [73/100] train_loss: 3.9957, val_loss: 3.9957, lr: 0.000001, 0.06s
2023-04-10 15:50:03,511 - INFO - Saved model at 73
2023-04-10 15:50:03,511 - INFO - Val loss decrease from 3.9957 to 3.9957, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch73.tar
2023-04-10 15:50:03,550 - INFO - epoch complete!
2023-04-10 15:50:03,550 - INFO - evaluating now!
2023-04-10 15:50:03,576 - INFO - Epoch [74/100] train_loss: 3.9957, val_loss: 3.9957, lr: 0.000001, 0.07s
2023-04-10 15:50:03,583 - INFO - Saved model at 74
2023-04-10 15:50:03,584 - INFO - Val loss decrease from 3.9957 to 3.9957, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch74.tar
2023-04-10 15:50:03,619 - INFO - epoch complete!
2023-04-10 15:50:03,619 - INFO - evaluating now!
2023-04-10 15:50:03,642 - INFO - Epoch [75/100] train_loss: 3.9957, val_loss: 3.9956, lr: 0.000001, 0.06s
2023-04-10 15:50:03,650 - INFO - Saved model at 75
2023-04-10 15:50:03,650 - INFO - Val loss decrease from 3.9957 to 3.9956, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch75.tar
2023-04-10 15:50:03,690 - INFO - epoch complete!
2023-04-10 15:50:03,691 - INFO - evaluating now!
2023-04-10 15:50:03,713 - INFO - Epoch [76/100] train_loss: 3.9956, val_loss: 3.9956, lr: 0.000001, 0.06s
2023-04-10 15:50:03,721 - INFO - Saved model at 76
2023-04-10 15:50:03,721 - INFO - Val loss decrease from 3.9956 to 3.9956, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch76.tar
2023-04-10 15:50:03,769 - INFO - epoch complete!
2023-04-10 15:50:03,769 - INFO - evaluating now!
2023-04-10 15:50:03,791 - INFO - Epoch [77/100] train_loss: 3.9956, val_loss: 3.9955, lr: 0.000001, 0.07s
2023-04-10 15:50:03,798 - INFO - Saved model at 77
2023-04-10 15:50:03,798 - INFO - Val loss decrease from 3.9956 to 3.9955, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch77.tar
2023-04-10 15:50:03,834 - INFO - epoch complete!
2023-04-10 15:50:03,834 - INFO - evaluating now!
2023-04-10 15:50:03,858 - INFO - Epoch [78/100] train_loss: 3.9955, val_loss: 3.9955, lr: 0.000001, 0.06s
2023-04-10 15:50:03,866 - INFO - Saved model at 78
2023-04-10 15:50:03,866 - INFO - Val loss decrease from 3.9955 to 3.9955, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch78.tar
2023-04-10 15:50:03,904 - INFO - epoch complete!
2023-04-10 15:50:03,904 - INFO - evaluating now!
2023-04-10 15:50:03,928 - INFO - Epoch [79/100] train_loss: 3.9955, val_loss: 3.9954, lr: 0.000001, 0.06s
2023-04-10 15:50:03,935 - INFO - Saved model at 79
2023-04-10 15:50:03,936 - INFO - Val loss decrease from 3.9955 to 3.9954, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch79.tar
2023-04-10 15:50:03,970 - INFO - epoch complete!
2023-04-10 15:50:03,970 - INFO - evaluating now!
2023-04-10 15:50:03,991 - INFO - Epoch [80/100] train_loss: 3.9954, val_loss: 3.9954, lr: 0.000001, 0.06s
2023-04-10 15:50:03,999 - INFO - Saved model at 80
2023-04-10 15:50:03,999 - INFO - Val loss decrease from 3.9954 to 3.9954, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch80.tar
2023-04-10 15:50:04,035 - INFO - epoch complete!
2023-04-10 15:50:04,036 - INFO - evaluating now!
2023-04-10 15:50:04,056 - INFO - Epoch [81/100] train_loss: 3.9954, val_loss: 3.9953, lr: 0.000001, 0.06s
2023-04-10 15:50:04,064 - INFO - Saved model at 81
2023-04-10 15:50:04,064 - INFO - Val loss decrease from 3.9954 to 3.9953, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch81.tar
2023-04-10 15:50:04,105 - INFO - epoch complete!
2023-04-10 15:50:04,105 - INFO - evaluating now!
2023-04-10 15:50:04,126 - INFO - Epoch [82/100] train_loss: 3.9953, val_loss: 3.9953, lr: 0.000001, 0.06s
2023-04-10 15:50:04,134 - INFO - Saved model at 82
2023-04-10 15:50:04,134 - INFO - Val loss decrease from 3.9953 to 3.9953, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch82.tar
2023-04-10 15:50:04,177 - INFO - epoch complete!
2023-04-10 15:50:04,177 - INFO - evaluating now!
2023-04-10 15:50:04,200 - INFO - Epoch [83/100] train_loss: 3.9953, val_loss: 3.9953, lr: 0.000001, 0.07s
2023-04-10 15:50:04,208 - INFO - Saved model at 83
2023-04-10 15:50:04,208 - INFO - Val loss decrease from 3.9953 to 3.9953, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch83.tar
2023-04-10 15:50:04,247 - INFO - epoch complete!
2023-04-10 15:50:04,247 - INFO - evaluating now!
2023-04-10 15:50:04,274 - INFO - Epoch [84/100] train_loss: 3.9953, val_loss: 3.9952, lr: 0.000001, 0.07s
2023-04-10 15:50:04,281 - INFO - Saved model at 84
2023-04-10 15:50:04,281 - INFO - Val loss decrease from 3.9953 to 3.9952, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch84.tar
2023-04-10 15:50:04,322 - INFO - epoch complete!
2023-04-10 15:50:04,323 - INFO - evaluating now!
2023-04-10 15:50:04,348 - INFO - Epoch [85/100] train_loss: 3.9952, val_loss: 3.9952, lr: 0.000001, 0.07s
2023-04-10 15:50:04,356 - INFO - Saved model at 85
2023-04-10 15:50:04,356 - INFO - Val loss decrease from 3.9952 to 3.9952, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch85.tar
2023-04-10 15:50:04,394 - INFO - epoch complete!
2023-04-10 15:50:04,394 - INFO - evaluating now!
2023-04-10 15:50:04,417 - INFO - Epoch [86/100] train_loss: 3.9952, val_loss: 3.9951, lr: 0.000001, 0.06s
2023-04-10 15:50:04,426 - INFO - Saved model at 86
2023-04-10 15:50:04,426 - INFO - Val loss decrease from 3.9952 to 3.9951, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch86.tar
2023-04-10 15:50:04,478 - INFO - epoch complete!
2023-04-10 15:50:04,478 - INFO - evaluating now!
2023-04-10 15:50:04,502 - INFO - Epoch [87/100] train_loss: 3.9951, val_loss: 3.9951, lr: 0.000001, 0.08s
2023-04-10 15:50:04,509 - INFO - Saved model at 87
2023-04-10 15:50:04,509 - INFO - Val loss decrease from 3.9951 to 3.9951, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch87.tar
2023-04-10 15:50:04,548 - INFO - epoch complete!
2023-04-10 15:50:04,548 - INFO - evaluating now!
2023-04-10 15:50:04,573 - INFO - Epoch [88/100] train_loss: 3.9951, val_loss: 3.9950, lr: 0.000001, 0.06s
2023-04-10 15:50:04,580 - INFO - Saved model at 88
2023-04-10 15:50:04,580 - INFO - Val loss decrease from 3.9951 to 3.9950, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch88.tar
2023-04-10 15:50:04,624 - INFO - epoch complete!
2023-04-10 15:50:04,625 - INFO - evaluating now!
2023-04-10 15:50:04,651 - INFO - Epoch [89/100] train_loss: 3.9950, val_loss: 3.9950, lr: 0.000001, 0.07s
2023-04-10 15:50:04,659 - INFO - Saved model at 89
2023-04-10 15:50:04,659 - INFO - Val loss decrease from 3.9950 to 3.9950, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch89.tar
2023-04-10 15:50:04,700 - INFO - epoch complete!
2023-04-10 15:50:04,700 - INFO - evaluating now!
2023-04-10 15:50:04,723 - INFO - Epoch [90/100] train_loss: 3.9950, val_loss: 3.9949, lr: 0.000001, 0.06s
2023-04-10 15:50:04,731 - INFO - Saved model at 90
2023-04-10 15:50:04,731 - INFO - Val loss decrease from 3.9950 to 3.9949, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch90.tar
2023-04-10 15:50:04,774 - INFO - epoch complete!
2023-04-10 15:50:04,774 - INFO - evaluating now!
2023-04-10 15:50:04,796 - INFO - Epoch [91/100] train_loss: 3.9949, val_loss: 3.9949, lr: 0.000001, 0.06s
2023-04-10 15:50:04,804 - INFO - Saved model at 91
2023-04-10 15:50:04,804 - INFO - Val loss decrease from 3.9949 to 3.9949, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch91.tar
2023-04-10 15:50:04,839 - INFO - epoch complete!
2023-04-10 15:50:04,840 - INFO - evaluating now!
2023-04-10 15:50:04,863 - INFO - Epoch [92/100] train_loss: 3.9949, val_loss: 3.9949, lr: 0.000001, 0.06s
2023-04-10 15:50:04,870 - INFO - Saved model at 92
2023-04-10 15:50:04,870 - INFO - Val loss decrease from 3.9949 to 3.9949, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch92.tar
2023-04-10 15:50:04,906 - INFO - epoch complete!
2023-04-10 15:50:04,907 - INFO - evaluating now!
2023-04-10 15:50:04,928 - INFO - Epoch [93/100] train_loss: 3.9949, val_loss: 3.9948, lr: 0.000001, 0.06s
2023-04-10 15:50:04,936 - INFO - Saved model at 93
2023-04-10 15:50:04,936 - INFO - Val loss decrease from 3.9949 to 3.9948, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch93.tar
2023-04-10 15:50:04,975 - INFO - epoch complete!
2023-04-10 15:50:04,975 - INFO - evaluating now!
2023-04-10 15:50:04,999 - INFO - Epoch [94/100] train_loss: 3.9948, val_loss: 3.9948, lr: 0.000001, 0.06s
2023-04-10 15:50:05,008 - INFO - Saved model at 94
2023-04-10 15:50:05,008 - INFO - Val loss decrease from 3.9948 to 3.9948, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch94.tar
2023-04-10 15:50:05,047 - INFO - epoch complete!
2023-04-10 15:50:05,047 - INFO - evaluating now!
2023-04-10 15:50:05,070 - INFO - Epoch [95/100] train_loss: 3.9948, val_loss: 3.9947, lr: 0.000001, 0.06s
2023-04-10 15:50:05,078 - INFO - Saved model at 95
2023-04-10 15:50:05,078 - INFO - Val loss decrease from 3.9948 to 3.9947, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch95.tar
2023-04-10 15:50:05,117 - INFO - epoch complete!
2023-04-10 15:50:05,118 - INFO - evaluating now!
2023-04-10 15:50:05,138 - INFO - Epoch [96/100] train_loss: 3.9947, val_loss: 3.9947, lr: 0.000001, 0.06s
2023-04-10 15:50:05,146 - INFO - Saved model at 96
2023-04-10 15:50:05,146 - INFO - Val loss decrease from 3.9947 to 3.9947, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch96.tar
2023-04-10 15:50:05,192 - INFO - epoch complete!
2023-04-10 15:50:05,193 - INFO - evaluating now!
2023-04-10 15:50:05,216 - INFO - Epoch [97/100] train_loss: 3.9947, val_loss: 3.9946, lr: 0.000001, 0.07s
2023-04-10 15:50:05,223 - INFO - Saved model at 97
2023-04-10 15:50:05,224 - INFO - Val loss decrease from 3.9947 to 3.9946, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch97.tar
2023-04-10 15:50:05,268 - INFO - epoch complete!
2023-04-10 15:50:05,268 - INFO - evaluating now!
2023-04-10 15:50:05,293 - INFO - Epoch [98/100] train_loss: 3.9946, val_loss: 3.9946, lr: 0.000001, 0.07s
2023-04-10 15:50:05,301 - INFO - Saved model at 98
2023-04-10 15:50:05,301 - INFO - Val loss decrease from 3.9946 to 3.9946, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch98.tar
2023-04-10 15:50:05,340 - INFO - epoch complete!
2023-04-10 15:50:05,341 - INFO - evaluating now!
2023-04-10 15:50:05,362 - INFO - Epoch [99/100] train_loss: 3.9946, val_loss: 3.9945, lr: 0.000001, 0.06s
2023-04-10 15:50:05,370 - INFO - Saved model at 99
2023-04-10 15:50:05,370 - INFO - Val loss decrease from 3.9946 to 3.9945, saving to ./libcity/cache/50001/model_cache/RNN_Xiongan_epoch99.tar
2023-04-10 15:50:05,370 - INFO - Trained totally 100 epochs, average train time is 0.040s, average eval time is 0.023s
2023-04-10 15:50:05,380 - INFO - Loaded model at 99
2023-04-10 15:50:05,380 - INFO - Saved model at ./libcity/cache/50001/model_cache/GRU_Xiongan.m
2023-04-10 15:50:05,387 - INFO - Start evaluating ...
2023-04-10 15:50:05,563 - INFO - Note that you select the single mode to evaluate!
2023-04-10 15:50:05,568 - INFO - Evaluate result is saved at ./libcity/cache/50001/evaluate_cache/2023_04_10_15_50_05_RNN_Xiongan.csv
2023-04-10 15:50:05,581 - INFO - 
         MAE      MAPE        MSE      RMSE  masked_MAE  masked_MAPE  masked_MSE  masked_RMSE        R2      EVAR
1   2.230092  0.037297  12.287292  3.505323    2.230092     0.037297   12.287292     3.505323  0.595770  0.597192
2   3.327570  0.055684  20.382071  4.514651    3.327570     0.055684   20.382071     4.514651  0.376309  0.377915
3   4.012453  0.069001  27.131676  5.208807    4.012453     0.069001   27.131676     5.208807  0.203201  0.211143
4   4.116233  0.069286  26.667940  5.164101    4.116233     0.069286   26.667940     5.164101  0.198810  0.198841
5   4.295671  0.071587  28.265242  5.316506    4.295671     0.071587   28.265242     5.316506  0.111318  0.116584
6   4.129789  0.069615  27.351294  5.229846    4.129789     0.069615   27.351294     5.229846  0.175677  0.175972
7   4.291564  0.073067  28.898844  5.375764    4.291564     0.073067   28.898844     5.375764  0.091295  0.092710
8   4.445208  0.075385  30.204252  5.495840    4.445208     0.075385   30.204252     5.495840  0.113896  0.114328
9   4.330501  0.073312  29.236362  5.407066    4.330501     0.073312   29.236362     5.407066  0.129026  0.129027
10  4.431842  0.074059  31.557770  5.617630    4.431842     0.074059   31.557770     5.617630  0.076622  0.078483
11  4.453346  0.075815  32.266026  5.680319    4.453346     0.075815   32.266026     5.680319  0.036820  0.038135
12  3.870319  0.065340  24.401165  4.939754    3.870319     0.065340   24.401165     4.939754  0.250687  0.251341
